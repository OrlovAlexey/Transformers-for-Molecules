{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdcMxVGEA9Cd"
   },
   "source": [
    "# **Graph Classification with ðŸ¤— Transformers**\n",
    "\n",
    "This notebook shows how to fine-tune the Graphormer model for Graph Classification on a dataset available on the hub. The idea is to add a randomly initialized classification head on top of a pre-trained encoder, and fine-tune the model altogether on a labeled dataset.\n",
    "\n",
    "Depending on the model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those two parameters, then the rest of the notebook should run smoothly.\n",
    "\n",
    "In this notebook, we'll fine-tune from the https://huggingface.co/clefourrier/pcqm4mv2-graphormer-base checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlArTG8KChJf"
   },
   "source": [
    "Before we start, let's install the `datasets` and `transformers` libraries, as well as Cython, on which this model depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1532RVbJgQV",
    "outputId": "1d92a15b-0efd-4b09-b006-56384c64943b"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U datasets transformers>=4.27.2 Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snZ1tmaOC412"
   },
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries. Transformers version must be > 4.27.2.\n",
    "\n",
    "We check that Cython is correctly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import is_cython_available\n",
    "print(\"Cython is installed:\", is_cython_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize your graphs, you also need to install `matplotlib` and `networkx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U matplotlib networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your token:\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "f1760b8ccf9b4c32977a1e83f3a3af3d",
      "e276e653c187474dba7e1c4fede10b79",
      "a6d024d44a6c49eebef7966ef5a836f1",
      "344c041a34b5458eb1bbb3ea8fa5b315",
      "18f7dc9f5e6241138534b7cf9aa30adb",
      "d5e3a1de2a4645639c029a404d04dc1c",
      "e7e938eb6baf486e829ea5d4734087cf",
      "730378e114f944908aa06f42bb2faa3d",
      "f73b5464140d4723b1b3f46796d9b1ca",
      "16ffe85c44764fa9ad8a31fb21e6432f",
      "40db3808e98d424cacc5d0fed54b9eaa",
      "e9bad1a707f0442da6f117fdd2804f72",
      "a0bac01e342b4793b66d7d4f5bfac2e2",
      "b447ca05136342d0a167bfb133a353bd",
      "4dcbcf9b086f452d9d1bc07b4a4cc1d3",
      "724b578bac3f4b7cb6806ee3c45aff01",
      "6ca86c47e547426e8a0d4487a786c46c"
     ]
    },
    "id": "Bkpk_JPlCww8",
    "outputId": "d80cb8c7-5382-427b-e90b-bfec7afdc052"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ0986jTDZRC"
   },
   "source": [
    "\n",
    "Then you need to install Git-LFS to upload your model checkpoints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XalxdrirGkLl"
   },
   "source": [
    "## Fine-tuning Graphormer on an graph classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnRWZSq0GRRh"
   },
   "source": [
    "In this notebook, we will see how to fine-tune the Graphormer model on [ðŸ¤— Transformers](https://github.com/huggingface/transformers) on a Graph Classification dataset.\n",
    "\n",
    "Given a graph, the goal is to predict its class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcE455KaG687"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD_G2KJgG_bU"
   },
   "source": [
    "Loading a graph dataset from the Hub is very easy. Let's load the `ogbg-molhiv` dataset, stored in the `OGB` repository. \n",
    "*To find other graph datasets, look for the \"Graph Machine Learning\" tag on the hub:  [here](https://huggingface.co/datasets?task_categories=task_categories:graph-ml&sort=downloads). You'll find social graphs, molecular datasets, some artificial ones, etc!*\n",
    "\n",
    "This dataset contains a collection of molecules (from MoleculeNet), and the goal is to predict if they to inhibit HIV or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250,
     "referenced_widgets": [
      "65ee9c937e37404593bbd78489040d82",
      "5d2d1f1d210449b895820a81089f6c0b",
      "6126aa9e8dd343aa9233ac1f2150121b",
      "c096392e55374751b33105be96d37934",
      "aba0dcd1eef34146a52c90eb5c3e211c",
      "db5bdd6de3e74610b61b044c23700daa",
      "eec1d3b8ea07492d9a4fb06bce7404d2",
      "d089ec92b52b4b90b7ade4a2b6d7ced4",
      "706b3ef455424cd5b0f2629d58b5aaa6",
      "b274626ba7bb4917843c2505e2e642d8",
      "c869a350dd09430cb3599a1b764abf7c",
      "7344011c60a44af49dfb435e217ba205",
      "a9a3933138f04b628d9ec9e0a1b3531b",
      "07a8dfd811d54c1eaaf8d30df4a15e02",
      "ac6e0d722fbf4cb98e1beae1d768461d",
      "73be6beffebe4986b26fd275a549983a",
      "9824e85405d64dbd8d1c28466cbd5ce2",
      "a18df3c4ad3d436ca9bb05e7e3700142",
      "4cbb9fa91c7b480e8152248e339da888",
      "4122b532a6674fdebc76dbf4bf064e4d",
      "e046e82af8894041bf83190eda1fdd27",
      "2953a9b8d7224f249d8fbe6b1eea0043",
      "2c017c8365c7417f80040637f0576456",
      "bad41d5acc1741e0a3954363802efb95",
      "d497d019f02048ed8d8996a7dc024086",
      "cf7f56acd6a84ab0bbd669ffc68049f1",
      "711229887a3c44308d99a36b0cfe383c",
      "9a6de936af954c528cad23494762d985",
      "6146998af3154b7d9317375018b0b35c",
      "3423d126316b4895b8350cad294e9ed5",
      "b47ec013328e427e91d645219ee0b4f3",
      "b1f48ef2e4774d3991109a3537ce6f95",
      "2daba079b8ab4a6bb5c9d4e975954913",
      "b5e61543921d41c1a0fd0bdd32042c30",
      "6be6e59a99cc4a7a9519f56274eab245",
      "c31e69612cc949569d72927dc8556167",
      "84731a7392f34547a8702ce8dae4ffde",
      "a4cdb122648b434fbc97a70c8ecd2797",
      "1ae00749a1db45f3a9df07d54ba7b9a2",
      "e3f9fa06f3254786babef77b69edf5e1",
      "c9578be641994795aebba19c76e18c7c",
      "dbc2646034c14ff798611f6a43ecfcb5",
      "0789ac7948dc47af88cbd4306376fa2a",
      "33ff92cb74cd45a0b04744e6a0aaa202",
      "78de59096c0c4f4088248d49d8e945c7",
      "0ef55f103c7049ffb072be07cbdc3c55",
      "d3cc200a473f4d05b003159452dc4694",
      "f558d858617649a683a8249dd93cfb15",
      "ec72f31db8fd4c209f081e20d43d9f01",
      "0eed61f5a8244ad0b7b02fdf2f0bc445",
      "07aba02933d5483c9db8d523957c26da",
      "2e436c1f1346463fbb4bd4365b91ebb8",
      "337cdba2a3a542229a2bfaa42cc9dbe4",
      "8da2a3d279654ff68534ac1ec0e4c94c",
      "62f3666095fd4f299875d99365fc6d3e",
      "f8204cbc9e33434e8dae692826092def",
      "89c3832e2105480bbc80c97683f8a9c6",
      "9bb0bb71bd3c4218be04f6e0dba884ab",
      "5466f882ca23480ab8d25a93d938c650",
      "eaa2e37efec944549715e9f5f12527b0",
      "4aed4abfe24d492ab793be6a5742c01e",
      "1ed8401e795b4efda2d6ce57b72aeafb",
      "150f5046c3224c0d9eff3f8c851b146f",
      "8a3c971f5628488c83a8cc3685f39e6b",
      "76bc21ca1ac541a29751df47a6b66eb6",
      "c48f86ba50054f70922cb6b86fc041c0"
     ]
    },
    "id": "Mp9xJcHP2TTP",
    "outputId": "c672111a-f1c1-4891-e60c-941bbd7751db"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "dataset = load_dataset(\"OGB/ogbg-molhiv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq8mwsZU2j6t"
   },
   "source": [
    "Let us also load the Accuracy metric, which we'll use to evaluate our model both during and after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "121d965ef7fb4d2fa4a5ccd17cbde89e",
      "55c3d0b36f004800976e85d830f81743",
      "ac029057d6534c9191fe3f1fddbd64fe",
      "32c8f368ff21452fb711fdce75f99a5a",
      "45649d5553544d479c5312c8a46637fb",
      "d1c68503e1bd4802b5077a14225909e4",
      "19e065315da84ab0bcfe771280b7cefc",
      "75099c97172c41b2ab9ce93fb8648f3a",
      "7d91643c73094ab990f7fadeded7ce32",
      "e770a085eccb42ffa19ccef7c2595baf",
      "7a23e83ece094f5b98e6cd715c78bff8"
     ]
    },
    "id": "8UGse36eLeeb",
    "outputId": "1e45d0bf-23e8-4a3a-c79e-0b27b75df5fe"
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8mTmFdlHOmN"
   },
   "source": [
    "The `dataset` object itself is a [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key per split (in this case, \"train\", \"validation\" and \"test\" splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tjOWPQYLq4u",
    "outputId": "ea00d557-228e-4264-f741-c03e6fd2ed99"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfPPNjthI3u2"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BujWoSgyMQlw",
    "outputId": "f38ca431-6ed5-4702-fe9b-0611cae82eec"
   },
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_100k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9g0APa21I_Rx"
   },
   "source": [
    "Each example consists of an graph (made of its nodes, edges, and optional features) and a corresponding label. We can also verify this by checking the features of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnnL3yHBI7Z3",
    "outputId": "8d21d2df-af8b-41e1-b70f-a50a132c3415"
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ7rLOsAkJ8F"
   },
   "source": [
    "We can inspect the graph using networkx and pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "32iolZyTkNlI",
    "outputId": "270751de-fab9-4759-d500-a5d5a62c8d0e"
   },
   "outputs": [],
   "source": [
    "# We want to plot the first train graph\n",
    "graph = dataset[\"train\"][0]\n",
    "\n",
    "edges = graph[\"edge_index\"]\n",
    "num_edges = len(edges[0])\n",
    "num_nodes = graph[\"num_nodes\"]\n",
    "\n",
    "# Conversion to networkx format\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "G.add_edges_from([(edges[0][i], edges[1][i]) for i in range(num_edges)])\n",
    "\n",
    "# Plot\n",
    "nx.draw(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMH8dh9w7I86"
   },
   "source": [
    "Let's print the corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFYtvw4I7KS2",
    "outputId": "6dc38e86-379e-4941-b220-d2dffb45aca6"
   },
   "outputs": [],
   "source": [
    "print(\"Label:\", graph['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zxoikSOjs0K"
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTupOU88p1lK"
   },
   "source": [
    "Graph transformer frameworks usually apply specific preprocessing to their datasets to generate added features and properties which help the underlying learning task (classification in our case).\n",
    "\n",
    "Here, we use Graphormer's default preprocessing, which generates in/out degree information, the shortest path between node matrices, and other properties of interest for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352,
     "referenced_widgets": [
      "fffb14323cbb485fbc251377f0df82be",
      "a99c93dcd98943aa9af6d6ae9cacb342",
      "36cb688ec8c048b9b67feeb978d1ae7e",
      "db6d4fa6175348ba9cb7e12d755c1b70",
      "153ac1ceef154fb1a7d080fb4b00ca67",
      "d70e71438f0945319eec5f2eedf804e5",
      "1a13206aae6346cfb744f0edca13dfae",
      "41556a6c7cf545ac9355482538ac814a",
      "7ce25ef57ec94306a781b46074f137fe",
      "822db9328a764186b4c71dc3a0788025",
      "2ff8584bc3ba4faa8dd305b4aa4e1023"
     ]
    },
    "id": "G1bX4lGAO_d9",
    "outputId": "004fa57f-dd57-47d1-f1f6-a98e6adba377"
   },
   "outputs": [],
   "source": [
    "from transformers.models.graphormer.collating_graphormer import preprocess_item, GraphormerDataCollator\n",
    "\n",
    "dataset_processed = dataset.map(preprocess_item, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P13tqfFTZ_F4"
   },
   "outputs": [],
   "source": [
    "# split up training into training + validation\n",
    "train_ds = dataset_processed['train']\n",
    "val_ds = dataset_processed['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMw_wQS58a7o"
   },
   "source": [
    "Let's access an element to look at all the features we've added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ng9TAlDV8d7r",
    "outputId": "809c645e-c87e-4cb4-ac02-3ae9fbe7d73b"
   },
   "outputs": [],
   "source": [
    "print(train_ds[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOXmyPQ76Qv9"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a-2YT7O6ayC"
   },
   "source": [
    "Calling the `from_pretrained` method on our model downloads and caches the weights for us. As the number of classes (for prediction) is dataset dependent, we pass the new `num_classes` as well as `ignore_mismatched_sizes` alongside the `model_checkpoint`. This makes sure a custom classification head is created, specific to our task, hence likely different from the original decoder head. \n",
    "\n",
    "(When using a pretrained model, you must make sure the embeddings of your data have the same shape as the ones used to pretrain your model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "4dbffab93ea2497fa5e7d4a710230034",
      "2cd78732f3114043aab3b2c3b4216a18",
      "de3ae0562d2344dd9e2055015e160a2c",
      "d74498ae614e412bbb47f33a830be7ba",
      "cdd3559a361e469bb26501c272e563ba",
      "45b2401d4c2042eeaa566aecaab3bd8f",
      "a688efdb9d114f4c91cac8a70f7322b0",
      "5830dd2340a64f1a874332b0b1e32ec7",
      "1ec40e8e33474dcb85bbf394eefc1b56",
      "e1f9aa53a0d4470a98206fb0322730b3",
      "c94af069c1674edf9b372c350d9b9c51",
      "fe0a9c76f4de441d9bd8de7394ffbcda",
      "21aa0de2c357460c926cd51ef2706ab1",
      "35274b3dd11c4d7ebe7912d04b706ebe",
      "76fde2f98f774466bb826c5cc3f90657",
      "edc7e95a57304afa9fb626e23e334e7b",
      "29c5dda2d3464ab0b6e3f5667dab9185",
      "d8fbaac013d24e0b9be1d0969bede5c1",
      "a721cfb1ad374676b542167485d7f462",
      "d7c49b2687b647a882348bd671ac8045",
      "01c63ad383b44a238cb7d931bdbc426e",
      "0e2c6500a66e42b19df8306e84229b14"
     ]
    },
    "id": "X9DDujL0q1ac",
    "outputId": "8328aab3-ff64-4dc7-d395-eaaa746fd0fa"
   },
   "outputs": [],
   "source": [
    "from transformers import GraphormerForGraphClassification\n",
    "\n",
    "model_checkpoint = \"clefourrier/graphormer-base-pcqm4mv2\" # pre-trained model from which to fine-tune\n",
    "\n",
    "model = GraphormerForGraphClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_classes=2,\n",
    "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8EmET_f6458"
   },
   "source": [
    "The warning is telling us we are throwing away some weights (the weights and bias of the `classifier` layer) and randomly initializing some other (the weights and bias of a new `classifier` layer). This is expected in this case, because we are adding a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEfyuq1U8hDT"
   },
   "source": [
    "To instantiate a `Trainer`, we will need to define the training configuration and the evaluation metric. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model.\n",
    "\n",
    "For graph datasets, it is particularly important to play around with batch sizes and gradient accumulation steps to train on enough samples while avoiding out-of-memory errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xc_MTm0Ks3DF"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    \"graph-classification\",\n",
    "    logging_dir=\"graph-classification\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    auto_find_batch_size=True, # batch size can be changed automatically to prevent OOMs\n",
    "    gradient_accumulation_steps=10,\n",
    "    dataloader_num_workers=4, \n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi6JYNYs8lJO"
   },
   "source": [
    "In the `Trainer` for graph classification, it is important to pass the specific data collator for the given graph dataset, which will convert individual graphs to batches for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVWfiBuv2uCS"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=GraphormerDataCollator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0PqjzHQVutb"
   },
   "source": [
    "We can now train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "398c087633254bcaaf781aa57e982dd6",
      "f200c07beda8456a92e897ee00b5fde5",
      "1f66f9bb6f374902ac87747b55fdede6",
      "fb8b8971f3714b16ac699a0bb9435dae",
      "b14bfd13a6294a9cb6f8226d43b2ba3d",
      "1de73b85fab34677b26258cf81b1f12f",
      "5ad22e5e6c7c464c8ac943b9730954a1",
      "dfe11154745547058a1158a2e8c7d620",
      "950d18b052794bdd85e9981dba17d253",
      "a98957fcd9204fdc83a14bb710da2fd8",
      "6da1bfe89c754d74868af73bff068ebb",
      "898560cd6bca49d7bbc530070737e348",
      "cb6c133b4a524edd98b35f43d4feef0e",
      "85aa3489e82442d38d387e9a1df8d920",
      "51b8c526e3594d3cac19c923160d082c",
      "0f5ce894e0ee47c6af02f709256ac641",
      "56ec636f14e749e1abc2d910c4ee08d7",
      "97d07155fabd42e580e130b4f1b50bff",
      "9d3a80f84461463da2d7135da04d0b8d",
      "dd7bebb0ca9c473aab467b9c22105bf8",
      "536f6919a19d435e9f19055eacdf143e",
      "111d49a2cbd142b79d50252805c79285"
     ]
    },
    "id": "Pps61vF_4QaH",
    "outputId": "b79a2940-d366-49f6-ec9c-d4b862485777"
   },
   "outputs": [],
   "source": [
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymwN-SIR-NDF"
   },
   "source": [
    "You can now upload the result of the training to the Hub with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "bdbc14917682409886e9e1571dd525e7",
      "98fd9150cbf045ac9443dcabe99ca22e",
      "dc22cc2ba2a94f56b56672c6ce19041d",
      "a722d5be4ebc42a38ed208047773c3ac",
      "bcd45d9e90d14473a743ce1e41968560",
      "dcb84839bd7f473a81d382e1fa0d69c8",
      "b13db65ff9d04f6d95eb5761d1df9c78",
      "5ca400da4dc0421288dc4788f0dde96c",
      "9a6e68f68baf4d41ae4668f119e1d461",
      "20648d3f57564cf2a30fab10b12af123",
      "aec38c4c448d4b8083232bb50351a188"
     ]
    },
    "id": "4aNMErFz-GzX",
    "outputId": "aaba3412-c92d-4305-8f5b-f7146ada1a59"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
