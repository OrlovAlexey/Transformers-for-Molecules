{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb87046b-24e4-4963-ace0-615a30c7ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ecfp0'\n",
    "samples_count = '10M'\n",
    "model_name = f'molberto_{filename}_{samples_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effd7294-42cf-4de5-91d4-d6ab3fec2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_properties = ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['Unnamed: 0', 'Smiles', 'ecfp2', 'ecfp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be7ba5c57a349b5907b951ea88a5c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2372673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9f902e-7691-4256-883a-bd70f484a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Bioactivities</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>CX Acidic pKa</th>\n",
       "      <th>CX Basic pKa</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415.99</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>56.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2246728737 2245273601 1026928756 3217380708 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.25</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>42.23</td>\n",
       "      <td>3.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2246728737 3217380708 3218693969 3218693969 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>37.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.76</td>\n",
       "      <td>882399112 3217380708 3218693969 3217380708 882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>548.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>186.56</td>\n",
       "      <td>6.08</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2246728737 3217380708 3218693969 3217380708 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314.35</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>92.92</td>\n",
       "      <td>8.77</td>\n",
       "      <td>5.70</td>\n",
       "      <td>2246728737 3217380708 2041434490 3217380708 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372668</th>\n",
       "      <td>460.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>95.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2246728737 864674487 2246699815 864942730 3217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372669</th>\n",
       "      <td>382.42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>69.64</td>\n",
       "      <td>9.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864942730 3217380708 2132511834 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372670</th>\n",
       "      <td>844.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.05</td>\n",
       "      <td>359.42</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>2.35</td>\n",
       "      <td>847957139 3217380708 3218693969 3217380708 999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372671</th>\n",
       "      <td>480.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>90.09</td>\n",
       "      <td>11.49</td>\n",
       "      <td>7.19</td>\n",
       "      <td>847957139 2246699815 1026654305 847961216 8473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372672</th>\n",
       "      <td>321.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>50.42</td>\n",
       "      <td>8.24</td>\n",
       "      <td>1.03</td>\n",
       "      <td>864662311 3217380708 3218693969 3217380708 321...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2372673 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Molecular Weight  Bioactivities  AlogP  Polar Surface Area  \\\n",
       "0                  415.99            6.0   4.09               56.15   \n",
       "1                  215.25           51.0   2.79               42.23   \n",
       "2                  475.94            2.0   6.00               37.39   \n",
       "3                  548.59            1.0   6.37              186.56   \n",
       "4                  314.35           23.0   1.33               92.92   \n",
       "...                   ...            ...    ...                 ...   \n",
       "2372668            460.49            3.0   4.78               95.78   \n",
       "2372669            382.42            6.0   3.84               69.64   \n",
       "2372670            844.84            NaN   6.05              359.42   \n",
       "2372671            480.00            4.0   2.55               90.09   \n",
       "2372672            321.77            1.0   4.42               50.42   \n",
       "\n",
       "         CX Acidic pKa  CX Basic pKa  \\\n",
       "0                  NaN           NaN   \n",
       "1                 3.97           NaN   \n",
       "2                  NaN          7.76   \n",
       "3                 6.08          2.29   \n",
       "4                 8.77          5.70   \n",
       "...                ...           ...   \n",
       "2372668            NaN          0.68   \n",
       "2372669           9.49           NaN   \n",
       "2372670          -3.92          2.35   \n",
       "2372671          11.49          7.19   \n",
       "2372672           8.24          1.03   \n",
       "\n",
       "                                                     ecfp1  \n",
       "0        2246728737 2245273601 1026928756 3217380708 20...  \n",
       "1        2246728737 3217380708 3218693969 3218693969 32...  \n",
       "2        882399112 3217380708 3218693969 3217380708 882...  \n",
       "3        2246728737 3217380708 3218693969 3217380708 32...  \n",
       "4        2246728737 3217380708 2041434490 3217380708 32...  \n",
       "...                                                    ...  \n",
       "2372668  2246728737 864674487 2246699815 864942730 3217...  \n",
       "2372669  864942730 3217380708 2132511834 3217380708 321...  \n",
       "2372670  847957139 3217380708 3218693969 3217380708 999...  \n",
       "2372671  847957139 2246699815 1026654305 847961216 8473...  \n",
       "2372672  864662311 3217380708 3218693969 3217380708 321...  \n",
       "\n",
       "[2372673 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628bf71f-7af4-4eab-9fa2-e1bec5c7d682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage on NaNs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Molecular Weight      0.000000\n",
       "Bioactivities         0.039649\n",
       "AlogP                 0.025650\n",
       "Polar Surface Area    0.025650\n",
       "CX Acidic pKa         0.443230\n",
       "CX Basic pKa          0.370395\n",
       "ecfp1                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percentage on NaNs:')\n",
    "dataframe.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9131af22-72dd-4fee-b5b4-9a5b159030cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows without NaNs: 763202\n"
     ]
    }
   ],
   "source": [
    "rows_with_nans = dataframe['Molecular Weight'].isna() | \\\n",
    "                 dataframe['Bioactivities'].isna() | \\\n",
    "                 dataframe['AlogP'].isna() | \\\n",
    "                 dataframe['Polar Surface Area'].isna() | \\\n",
    "                 dataframe['CX Acidic pKa'].isna() | \\\n",
    "                 dataframe['CX Basic pKa'].isna()\n",
    "print(f'Count of rows without NaNs: {dataframe.shape[0] - dataframe.loc[rows_with_nans].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeec7baa-b6bb-47a1-bf4a-66e94049750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 2 last properties to reduce NaN counts\n",
    "molecular_properties = ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area']\n",
    "dataframe = dataframe.drop(columns=['CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1964f7f1-2efc-4333-81bc-3ebbdcbec934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN's\n",
    "dataframe = dataframe.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3b5a83-5050-48d4-8813-490c01fbc1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Bioactivities</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415.99</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>56.15</td>\n",
       "      <td>2246728737 2245273601 1026928756 3217380708 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.25</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>42.23</td>\n",
       "      <td>2246728737 3217380708 3218693969 3218693969 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>37.39</td>\n",
       "      <td>882399112 3217380708 3218693969 3217380708 882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>548.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>186.56</td>\n",
       "      <td>2246728737 3217380708 3218693969 3217380708 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314.35</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>92.92</td>\n",
       "      <td>2246728737 3217380708 2041434490 3217380708 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220510</th>\n",
       "      <td>398.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.72</td>\n",
       "      <td>99.43</td>\n",
       "      <td>2246728737 2245384272 2092489639 3217380708 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220511</th>\n",
       "      <td>460.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>95.78</td>\n",
       "      <td>2246728737 864674487 2246699815 864942730 3217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220512</th>\n",
       "      <td>382.42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>69.64</td>\n",
       "      <td>864942730 3217380708 2132511834 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220513</th>\n",
       "      <td>480.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>90.09</td>\n",
       "      <td>847957139 2246699815 1026654305 847961216 8473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220514</th>\n",
       "      <td>321.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>50.42</td>\n",
       "      <td>864662311 3217380708 3218693969 3217380708 321...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2220515 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Molecular Weight  Bioactivities  AlogP  Polar Surface Area  \\\n",
       "0                  415.99            6.0   4.09               56.15   \n",
       "1                  215.25           51.0   2.79               42.23   \n",
       "2                  475.94            2.0   6.00               37.39   \n",
       "3                  548.59            1.0   6.37              186.56   \n",
       "4                  314.35           23.0   1.33               92.92   \n",
       "...                   ...            ...    ...                 ...   \n",
       "2220510            398.44            2.0   3.72               99.43   \n",
       "2220511            460.49            3.0   4.78               95.78   \n",
       "2220512            382.42            6.0   3.84               69.64   \n",
       "2220513            480.00            4.0   2.55               90.09   \n",
       "2220514            321.77            1.0   4.42               50.42   \n",
       "\n",
       "                                                     ecfp1  \n",
       "0        2246728737 2245273601 1026928756 3217380708 20...  \n",
       "1        2246728737 3217380708 3218693969 3218693969 32...  \n",
       "2        882399112 3217380708 3218693969 3217380708 882...  \n",
       "3        2246728737 3217380708 3218693969 3217380708 32...  \n",
       "4        2246728737 3217380708 2041434490 3217380708 32...  \n",
       "...                                                    ...  \n",
       "2220510  2246728737 2245384272 2092489639 3217380708 86...  \n",
       "2220511  2246728737 864674487 2246699815 864942730 3217...  \n",
       "2220512  864942730 3217380708 2132511834 3217380708 321...  \n",
       "2220513  847957139 2246699815 1026654305 847961216 8473...  \n",
       "2220514  864662311 3217380708 3218693969 3217380708 321...  \n",
       "\n",
       "[2220515 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e96ad73-2190-48f4-a1c3-ba4b5325f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1'],\n",
       "        num_rows: 1776412\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1'],\n",
       "        num_rows: 222052\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1'],\n",
       "        num_rows: 222051\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=15)\n",
    "\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=15)\n",
    "\n",
    "# 10% for test, 10 for validation, 80% for train\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'validation': test_valid['train']})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f3e06-7933-457f-a51d-0373c34f413a",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7720fb53-0a36-452f-8d5a-f23f0c5755d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.model_max_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f924833-477c-4a24-936e-d62f0ca5dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1776412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/222052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/222051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1776412\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 222052\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'ecfp1', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 222051\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"ecfp1\"], truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434caf18-e9b1-42ac-b40e-05c1b75c538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 13:22:10.394550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "columns = [\"input_ids\", \"attention_mask\"]\n",
    "columns.extend(molecular_properties) # our labels\n",
    "print(columns)\n",
    "tokenized_dataset.set_format('torch', columns=columns)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class MolecularPropertiesRegression(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_properties):\n",
    "        super(MolecularPropertiesRegression, self).__init__()\n",
    "        self.num_properties = num_properties\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n",
    "        # removing last layer of transformer\n",
    "        self.transformer.pooler = torch.nn.Identity()\n",
    "        # freezing transformer weights\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.regressor = torch.nn.Linear(768, num_properties)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        last_hidden_state = outputs[0]\n",
    "        # last_hidden_state is the shape of (batch_size=32, input_sequence_length=512, hidden_size=768)\n",
    "        # so we take only hidden emdedding for [CLS] token (first) as it contains the entire context\n",
    "        # and would be sufficient for simple downstream tasks such as classification/regression\n",
    "        predicted_property_values = self.regressor(last_hidden_state[:, 0, : ].view(-1, 768))\n",
    "\n",
    "        return predicted_property_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9748546b-71d1-4d74-a14d-3c5059f14c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/test/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at molberto_ecfp0_10M and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Identity()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how last layer is removed from Roberta\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "transformer = AutoModel.from_pretrained(model_name, config=config)\n",
    "transformer.pooler = torch.nn.Identity()\n",
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 1024, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = 512, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at molberto_ecfp0_10M and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\", index=2) if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = MolecularPropertiesRegression(model_name, num_properties=len(molecular_properties)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularPropertiesRegression(\n",
       "  (transformer): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Identity()\n",
       "  )\n",
       "  (regressor): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/test/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f78e178-f7c1-4fc0-b8ad-5c5d5e03281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3144654/1739285407.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metrics = { k: load_metric(\"mse\") for k in molecular_properties }\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# a metric for each property\n",
    "metrics = { k: load_metric(\"mse\") for k in molecular_properties }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65727367edf14be987edd8716450b11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9d6695a6e84ce7ac76d458e28debe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for Molecular Weight: {'mse': 161181.593241697}\n",
      "Metric for Bioactivities: {'mse': 182.00275182570348}\n",
      "Metric for AlogP: {'mse': 3.250546004155947}\n",
      "Metric for Polar Surface Area: {'mse': 5509.086779695163}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        labels_batch = { k: v.to(device) for k, v in batch.items() if k in molecular_properties }\n",
    "\n",
    "        labeled_property_values = torch.stack(list(labels_batch.values())).T\n",
    "        predicted_property_values = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(predicted_property_values, labeled_property_values)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        labels_batch = { k: v.to(device) for k, v in batch.items() if k in molecular_properties }\n",
    "\n",
    "        labeled_property_values = torch.stack(list(labels_batch.values())).T\n",
    "        with torch.no_grad():\n",
    "            predicted_property_values = model(**input_batch)\n",
    "\n",
    "        for i, molecular_property in enumerate(molecular_properties):\n",
    "            metrics[molecular_property].add_batch(predictions = [predicted_property_values[0][i]], references = [labeled_property_values[0][i]])\n",
    "        progress_bar_eval.update(1)\n",
    "    \n",
    "    for molecular_property in molecular_properties:\n",
    "        print(f'Metric for {molecular_property}:', metrics[molecular_property].compute()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
