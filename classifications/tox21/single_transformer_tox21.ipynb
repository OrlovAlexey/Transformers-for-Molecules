{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb87046b-24e4-4963-ace0-615a30c7ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ecfp0'\n",
    "samples_count1 = '10M'\n",
    "model_name1 = f'molberto_{filename}_{samples_count1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02ce751-fe8d-4ad6-9c49-00e349babff7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47985eff-f9a2-4c43-b1f2-2c9ed1968123",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effd7294-42cf-4de5-91d4-d6ab3fec2127",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 'NR-AR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad71dab-033f-4a6c-bfc1-ae0991f89cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45d58be-0cab-44f0-8c91-1fb0ba413178",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"tox21-ecfp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30f6d077179431987a61eba8feaa1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9f902e-7691-4256-883a-bd70f484a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
       "      <td>2246728737 864674487 3217380708 3218693969 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
       "      <td>3975275337 2076190208 1135286194 951226070 951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
       "      <td>932712697 252686949 589930590 3705139132 13780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
       "      <td>2246728737 2976816164 2968968094 2968968094 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
       "      <td>1861965050 778974661 2119439498 2117068077 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22753</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
       "      <td>3542456614 2251845666 3346582092 3119383463 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22754</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
       "      <td>464037414 2602615753 2681514009 1799979616 845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "      <td>2246728737 2245384272 864674487 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "      <td>3542456614 3994088662 2115476908 3162837314 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "      <td>2677858541 804536389 885026269 2944555726 2905...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22758 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  \\\n",
       "0        0.0        0.0     NaN           0.0    0.0        0.0   \n",
       "1        0.0        0.0     NaN           0.0    0.0        0.0   \n",
       "2        0.0        0.0     NaN           0.0    0.0        0.0   \n",
       "3        1.0        1.0     0.0           NaN    1.0        1.0   \n",
       "4        1.0        1.0     0.0           NaN    1.0        1.0   \n",
       "...      ...        ...     ...           ...    ...        ...   \n",
       "22753    0.0        0.0     0.0           0.0    0.0        0.0   \n",
       "22754    0.0        0.0     0.0           0.0    0.0        0.0   \n",
       "22755    0.0        0.0     1.0           NaN    NaN        0.0   \n",
       "22756    0.0        0.0     1.0           NaN    NaN        0.0   \n",
       "22757    0.0        0.0     1.0           NaN    NaN        0.0   \n",
       "\n",
       "       NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53  \\\n",
       "0                0.0     0.0       0.0     0.0     1.0     0.0   \n",
       "1                0.0     0.0       0.0     0.0     1.0     0.0   \n",
       "2                0.0     0.0       0.0     0.0     1.0     0.0   \n",
       "3                0.0     0.0       0.0     0.0     1.0     1.0   \n",
       "4                0.0     0.0       0.0     0.0     1.0     1.0   \n",
       "...              ...     ...       ...     ...     ...     ...   \n",
       "22753            0.0     NaN       0.0     NaN     0.0     0.0   \n",
       "22754            0.0     NaN       0.0     NaN     0.0     0.0   \n",
       "22755            0.0     1.0       0.0     0.0     0.0     0.0   \n",
       "22756            0.0     1.0       0.0     0.0     0.0     0.0   \n",
       "22757            0.0     1.0       0.0     0.0     0.0     0.0   \n",
       "\n",
       "                                                  Smiles  \\\n",
       "0                COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4   \n",
       "1                COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4   \n",
       "2                COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4   \n",
       "3      C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...   \n",
       "4      C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...   \n",
       "...                                                  ...   \n",
       "22753                          CCN1C(=O)NC(c2ccccc2)C1=O   \n",
       "22754                          CCN1C(=O)NC(c2ccccc2)C1=O   \n",
       "22755                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1   \n",
       "22756                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1   \n",
       "22757                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1   \n",
       "\n",
       "                                                    ecfp  \n",
       "0      2246728737 864674487 3217380708 3218693969 321...  \n",
       "1      3975275337 2076190208 1135286194 951226070 951...  \n",
       "2      932712697 252686949 589930590 3705139132 13780...  \n",
       "3      2246728737 2976816164 2968968094 2968968094 29...  \n",
       "4      1861965050 778974661 2119439498 2117068077 172...  \n",
       "...                                                  ...  \n",
       "22753  3542456614 2251845666 3346582092 3119383463 10...  \n",
       "22754  464037414 2602615753 2681514009 1799979616 845...  \n",
       "22755  2246728737 2245384272 864674487 3217380708 321...  \n",
       "22756  3542456614 3994088662 2115476908 3162837314 95...  \n",
       "22757  2677858541 804536389 885026269 2944555726 2905...  \n",
       "\n",
       "[22758 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a582801a-eea2-4d26-bf1f-cfc43804e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna(subset=[target]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a82e3ac-a264-4236-adf4-6462a67d062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = dataframe[0:3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628bf71f-7af4-4eab-9fa2-e1bec5c7d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Percentage on NaNs:')\n",
    "# dataframe.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9131af22-72dd-4fee-b5b4-9a5b159030cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_with_nans = dataframe['Molecular Weight'].isna() | \\\n",
    "#                  dataframe['Bioactivities'].isna() | \\\n",
    "#                  dataframe['AlogP'].isna() | \\\n",
    "#                  dataframe['Polar Surface Area'].isna() | \\\n",
    "#                  dataframe['CX Acidic pKa'].isna() | \\\n",
    "#                  dataframe['CX Basic pKa'].isna()\n",
    "# print(f'Count of rows without NaNs: {dataframe.shape[0] - dataframe.loc[rows_with_nans].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeec7baa-b6bb-47a1-bf4a-66e94049750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 2 last properties to reduce NaN counts\n",
    "# molecular_properties = ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area']\n",
    "# dataframe = dataframe.drop(columns=['CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1964f7f1-2efc-4333-81bc-3ebbdcbec934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN's\n",
    "# dataframe = dataframe.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b3b5a83-5050-48d4-8813-490c01fbc1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e96ad73-2190-48f4-a1c3-ba4b5325f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp'],\n",
       "        num_rows: 16876\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp'],\n",
       "        num_rows: 2110\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp'],\n",
       "        num_rows: 2110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=15)\n",
    "\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=15)\n",
    "\n",
    "# 10% for test, 10 for validation, 80% for train\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'validation': test_valid['train']})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f3e06-7933-457f-a51d-0373c34f413a",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7720fb53-0a36-452f-8d5a-f23f0c5755d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "tokenizer.model_max_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f924833-477c-4a24-936e-d62f0ca5dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f75033b0184fcfb63f47b41d1230e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16876 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15196cc36f8f414890e69cbf77585163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dad2a7c1548404da393f30192055024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16876\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2110\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53', 'Smiles', 'ecfp', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"ecfp\"], truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "434caf18-e9b1-42ac-b40e-05c1b75c538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'NR-AR']\n"
     ]
    }
   ],
   "source": [
    "columns = [\"input_ids\", \"attention_mask\"]\n",
    "columns.extend([target]) # our labels\n",
    "print(columns)\n",
    "tokenized_dataset.set_format('torch', columns=columns)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class MolecularPropertiesClassification(torch.nn.Module):\n",
    "    def __init__(self, model_name1):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "        \n",
    "        config1 = AutoConfig.from_pretrained(model_name1)\n",
    "        self.transformer1 = AutoModel.from_pretrained(model_name1, config=config1)\n",
    "        # removing last layer of transformer\n",
    "        self.transformer1.pooler = torch.nn.Identity()\n",
    "        # freezing transformer weights\n",
    "        for param in self.transformer1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(768, 2, bias=True)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs1 = self.transformer1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state1 = outputs1[0]\n",
    "        \n",
    "        first_linear_out = self.linear1(last_hidden_state1[:, 0, : ].view(-1, 768))\n",
    "        logits = self.linear2(torch.nn.functional.sigmoid(first_linear_out))\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at molberto_ecfp0_10M and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\", index=gpu_number) if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = MolecularPropertiesClassification(model_name1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularPropertiesClassification(\n",
       "  (transformer1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Identity()\n",
       "  )\n",
       "  (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33morlov-aleksei53\u001b[0m (\u001b[33mmoleculary-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alexeyorlov53/Transformers-for-Molecules/classifications/tox21/wandb/run-20241001_212049-pqsuw7uu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/pqsuw7uu' target=\"_blank\">ECFP-BERT-10M-Tox21</a></strong> to <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/pqsuw7uu' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer/runs/pqsuw7uu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/moleculary-ai/efcp_transformer/runs/pqsuw7uu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4d5c063280>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name='ECFP-BERT-' + samples_count1 + \"-Tox21\",\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac6a41255fd4cdcb881785138f23ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684757406d994257b2fd70a00fd89d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(logits.view(-1, 2), batch[target].view(-1).type(torch.cuda.LongTensor))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch[target]\n",
    "\n",
    "        print(pred_labels)\n",
    "        print(true_labels)\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "\n",
    "    train_loss = epoch_loss / len(train_dataloader)\n",
    "    train_accuracy = accuracy_score(total_true_labels, total_pred_labels)\n",
    "    train_f1_score = f1_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    train_precision = precision_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    train_recall = recall_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    train_roc_auc = roc_auc_score(total_true_labels, total_pred_labels)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch[target].view(-1).type(torch.cuda.LongTensor))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch[target]\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "\n",
    "    validation_loss = epoch_loss / len(eval_dataloader)\n",
    "    validation_accuracy = accuracy_score(total_true_labels, total_pred_labels)\n",
    "    validation_f1_score = f1_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    validation_precision = precision_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    validation_recall = recall_score(total_true_labels, total_pred_labels, average='micro')\n",
    "    validation_roc_auc = roc_auc_score(total_true_labels, total_pred_labels)\n",
    "\n",
    "    wandb.log({\"loss/train\": train_loss, \n",
    "               \"accuracy/train\": train_accuracy, \n",
    "               \"f1/train\": train_f1_score,\n",
    "               \"precision/train\": train_precision, \n",
    "               \"recall/train\": train_recall, \n",
    "               \"roc_auc_score/train\": train_roc_auc,\n",
    "               \n",
    "               \"loss/validation\": validation_loss, \n",
    "               \"accuracy/validation\": validation_accuracy, \n",
    "               \"f1/validation\": validation_f1_score, \n",
    "               \"precision/validation\": validation_precision, \n",
    "               \"recall/validation\": validation_recall, \n",
    "               \"roc_auc_score/validation\": validation_roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dda779-9490-476b-a2ed-eebd36ed7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch[target].view(-1).type(torch.cuda.LongTensor))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch[target]\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/test\": epoch_loss / len(test_dataloader)})\n",
    "    wandb.log({\"accuracy/test\": accuracy_score(total_true_labels, total_pred_labels)})\n",
    "    wandb.log({\"f1/test\": f1_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"precision/test\": precision_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"recall/test\": recall_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"roc_auc_score/test\": roc_auc_score(total_true_labels, total_pred_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce4e49-1829-4a80-8260-b32201681f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
