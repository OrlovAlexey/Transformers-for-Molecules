{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb87046b-24e4-4963-ace0-615a30c7ddeb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "filename = 'ecfp0'\n",
    "samples_count1 = '10M'\n",
    "model_name1 = f'molberto_{filename}_{samples_count1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b2dc1e-d62a-4867-b474-21ae19157b3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320f10e1-f3a1-4fbe-98ad-f0375f91fd0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "gpu_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cdadaf-70d4-40dd-9f6e-49a80afbca65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "target = 'CT_TOX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03dc1da-1594-497e-9464-3ac04584e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"clintox_with_ecfp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e65219cbaf4104bcfa6fc846c7c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1d9dd4-acce-41c4-838a-fa47600f0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>FDA_APPROVED</th>\n",
       "      <th>CT_TOX</th>\n",
       "      <th>ecfp0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2976033787 2976033787 2976033787 2976033787 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2245273601 2245273601 2245273601 2246699815 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4277593716 847954377 2246699815 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4277593716 847954377 2246699815 847957139 3217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[N+](=O)([O-])[O-]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>848127915 864942730 864942795 864942795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>O[Si](=O)O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>864662311 3387140397 864942730 864662311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>O=[Ti]=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>864942730 869071688 864942730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>O=[Zn]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>864942730 971583629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>OCl(=O)(=O)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>864662311 3858440414 864942795 864942795 86494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>S=[Se]=S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1026654305 3595956281 1026654305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  FDA_APPROVED  CT_TOX  \\\n",
       "0     [C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...             1       0   \n",
       "1     [C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...             1       0   \n",
       "2     [H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...             1       0   \n",
       "3     [H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...             1       0   \n",
       "4                                    [N+](=O)([O-])[O-]             1       0   \n",
       "...                                                 ...           ...     ...   \n",
       "1474                                         O[Si](=O)O             1       0   \n",
       "1475                                           O=[Ti]=O             1       0   \n",
       "1476                                             O=[Zn]             1       0   \n",
       "1477                                      OCl(=O)(=O)=O             1       0   \n",
       "1478                                           S=[Se]=S             1       0   \n",
       "\n",
       "                                                  ecfp0  \n",
       "0     2976033787 2976033787 2976033787 2976033787 29...  \n",
       "1     2245273601 2245273601 2245273601 2246699815 86...  \n",
       "2     4277593716 847954377 2246699815 3217380708 321...  \n",
       "3     4277593716 847954377 2246699815 847957139 3217...  \n",
       "4               848127915 864942730 864942795 864942795  \n",
       "...                                                 ...  \n",
       "1474           864662311 3387140397 864942730 864662311  \n",
       "1475                      864942730 869071688 864942730  \n",
       "1476                                864942730 971583629  \n",
       "1477  864662311 3858440414 864942795 864942795 86494...  \n",
       "1478                   1026654305 3595956281 1026654305  \n",
       "\n",
       "[1479 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b5c022-4c9e-427e-8962-9e19e6344dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna(subset=[target]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e96ad73-2190-48f4-a1c3-ba4b5325f62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0'],\n",
       "        num_rows: 1183\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0'],\n",
       "        num_rows: 148\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0'],\n",
       "        num_rows: 148\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=15)\n",
    "\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=15)\n",
    "\n",
    "# 10% for test, 10 for validation, 80% for train\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'validation': test_valid['train']})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f3e06-7933-457f-a51d-0373c34f413a",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7720fb53-0a36-452f-8d5a-f23f0c5755d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "tokenizer.model_max_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f924833-477c-4a24-936e-d62f0ca5dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c562c86ead48cea76bf041223b79d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4a9c341fee4230a25e595e5ab09e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df524a34f407481fb822090ad01f0921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1183\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 148\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'FDA_APPROVED', 'CT_TOX', 'ecfp0', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 148\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"ecfp0\"], truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434caf18-e9b1-42ac-b40e-05c1b75c538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'CT_TOX']\n"
     ]
    }
   ],
   "source": [
    "columns = [\"input_ids\", \"attention_mask\"]\n",
    "columns.extend([target]) # our labels\n",
    "print(columns)\n",
    "tokenized_dataset.set_format('torch', columns=columns)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class MolecularPropertiesClassification(torch.nn.Module):\n",
    "    def __init__(self, model_name1):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "\n",
    "        config1 = AutoConfig.from_pretrained(model_name1)\n",
    "        self.transformer1 = AutoModel.from_pretrained(model_name1, config=config1)\n",
    "        # removing last layer of transformer\n",
    "        self.transformer1.pooler = torch.nn.Identity()\n",
    "        # freezing transformer weights\n",
    "        for param in self.transformer1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(768, 2, bias=True)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs1 = self.transformer1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state1 = outputs1[0]\n",
    "        \n",
    "        first_linear_out = self.linear1(last_hidden_state1[:, 0, : ].view(-1, 768))\n",
    "        logits = self.linear2(torch.nn.functional.sigmoid(first_linear_out))\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], shuffle = True, batch_size = batch_size, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at molberto_ecfp0_10M and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\", index=gpu_number) if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = MolecularPropertiesClassification(model_name1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularPropertiesClassification(\n",
       "  (transformer1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Identity()\n",
       "  )\n",
       "  (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace84840-28b1-463d-8e46-c3019134f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Example labels; replace this with your actual label array\n",
    "labels = np.array([0]*(len(dataframe[target])-sum(dataframe[target])) + [1]*sum(dataframe[target]))  # 1367 False, 112 True\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c49808f5-9761-41c2-8c52-92cbeecef591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5410, 6.6027], device='cuda:2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3450ca13-def6-4f4a-8daf-26001911bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # Compute the cross-entropy loss\n",
    "        loss = -torch.sum(self.weights * targets * torch.log(probs + 1e-10), dim=1)\n",
    "        return torch.mean(loss)  # Return the average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "720074a8-a653-47af-88eb-daa82efd2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, targets):\n",
    "        loss_fn = WeightedCrossEntropyLoss(weights=class_weights.to(device))\n",
    "\n",
    "        e = torch.eye(2).to(device)\n",
    "        loss = loss_fn(logits, e[targets])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33morlov-aleksei53\u001b[0m (\u001b[33mmoleculary-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alexeyorlov53/Transformers-for-Molecules/classifications/clintox/wandb/run-20240927_113620-v5lyeuha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha' target=\"_blank\">ECFP-BERT-10M-ClinTox CT_TOX weighted_classes lr=5e-05</a></strong> to <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbd7b9a2370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name='ECFP-BERT-' + samples_count1 + \"-ClinTox\" + ' ' + target + \" weighted_classes\" + \" lr=\" + str(lr),\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335606bc1a9d42a7b1be6e021a1f2039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5213bb3b778e44a18495ea5781315e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        # loss = loss_func(logits.view(-1, 2), batch[target].view(-1))\n",
    "        loss = compute_loss(logits.view(-1, 2), batch[target].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch[target]\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/train\": epoch_loss / len(train_dataloader)})\n",
    "    wandb.log({\"accuracy/train\": accuracy_score(total_true_labels, total_pred_labels)})\n",
    "    wandb.log({\"f1/train\": f1_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"precision/train\": precision_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"recall/train\": recall_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"roc_auc_score/train\": roc_auc_score(total_true_labels, total_pred_labels)})\n",
    "\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            # loss = loss_func(logits.view(-1, 2), batch[target].view(-1))\n",
    "            loss = compute_loss(logits.view(-1, 2), batch[target].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch[target]\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)})\n",
    "    wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)})\n",
    "    wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"roc_auc_score/validation\": roc_auc_score(total_true_labels, total_pred_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6795e8e-e49a-4805-9b8c-4cacb3459268",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in test_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch[target] = batch[target].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            # loss = loss_func(logits.view(-1, 2), batch[target].view(-1))\n",
    "            loss = compute_loss(logits.view(-1, 2), batch[target].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch[target]\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/test\": epoch_loss / len(test_dataloader)})\n",
    "    wandb.log({\"accuracy/test\": accuracy_score(total_true_labels, total_pred_labels)})\n",
    "    wandb.log({\"f1/test\": f1_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"precision/test\": precision_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"recall/test\": recall_score(total_true_labels, total_pred_labels, average='micro')})\n",
    "    wandb.log({\"roc_auc_score/test\": roc_auc_score(total_true_labels, total_pred_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "327b85a2-4d86-4e08-a979-78d8dec1df3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>▁</td></tr><tr><td>accuracy/train</td><td>▁▅▄▆▆▇▇▅▆▅▆▆▇▆▆▇▆▇▇█▇▇██▇▇▇█▇█▇▇▇█▇███▇▇</td></tr><tr><td>accuracy/validation</td><td>▁▆▇▅█▇█▇▇▇██▇▇██▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>f1/test</td><td>▁</td></tr><tr><td>f1/train</td><td>▁▅▄▆▆▇▇▅▆▅▆▆▇▆▆▇▆▇▇█▇▇██▇▇▇█▇█▇▇▇█▇███▇▇</td></tr><tr><td>f1/validation</td><td>▁▆▇▅█▇█▇▇▇██▇▇██▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>loss/test</td><td>▁</td></tr><tr><td>loss/train</td><td>█▇▆▆▅▅▄▄▄▄▃▄▃▃▃▂▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂</td></tr><tr><td>loss/validation</td><td>█▆▅▄▅▄▂▃▃▂▂▃▃▂▅▃▂▃▂▄▁▂▃▁▄▂▃▁▅▁▃▁▄▃▂▃▂▂▂▃</td></tr><tr><td>precision/test</td><td>▁</td></tr><tr><td>precision/train</td><td>▁▅▄▆▆▇▇▅▆▅▆▆▇▆▆▇▆▇▇█▇▇██▇▇▇█▇█▇▇▇█▇███▇▇</td></tr><tr><td>precision/validation</td><td>▁▆▇▅█▇█▇▇▇██▇▇██▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>recall/test</td><td>▁</td></tr><tr><td>recall/train</td><td>▁▅▄▆▆▇▇▅▆▅▆▆▇▆▆▇▆▇▇█▇▇██▇▇▇█▇█▇▇▇█▇███▇▇</td></tr><tr><td>recall/validation</td><td>▁▆▇▅█▇█▇▇▇██▇▇██▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>roc_auc_score/test</td><td>▁</td></tr><tr><td>roc_auc_score/train</td><td>▁▅▅▆▆▆▇▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇██▇▇▇█▇█▇▇███▇█▇▇█</td></tr><tr><td>roc_auc_score/validation</td><td>▁▇█▄▄▇▄▅▆▇▅▄▆▆▅▄▆▆▅▅▆▆▅▆▅▆▆▆▆▆▅▅▅▆▆▆▆▆▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/test</td><td>0.72973</td></tr><tr><td>accuracy/train</td><td>0.74134</td></tr><tr><td>accuracy/validation</td><td>0.71622</td></tr><tr><td>f1/test</td><td>0.72973</td></tr><tr><td>f1/train</td><td>0.74134</td></tr><tr><td>f1/validation</td><td>0.71622</td></tr><tr><td>loss/test</td><td>0.5952</td></tr><tr><td>loss/train</td><td>0.5071</td></tr><tr><td>loss/validation</td><td>0.55905</td></tr><tr><td>precision/test</td><td>0.72973</td></tr><tr><td>precision/train</td><td>0.74134</td></tr><tr><td>precision/validation</td><td>0.71622</td></tr><tr><td>recall/test</td><td>0.72973</td></tr><tr><td>recall/train</td><td>0.74134</td></tr><tr><td>recall/validation</td><td>0.71622</td></tr><tr><td>roc_auc_score/test</td><td>0.68679</td></tr><tr><td>roc_auc_score/train</td><td>0.76923</td></tr><tr><td>roc_auc_score/validation</td><td>0.61594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ECFP-BERT-10M-ClinTox CT_TOX weighted_classes lr=5e-05</strong> at: <a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer/runs/v5lyeuha</a><br/> View project at: <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240927_113620-v5lyeuha/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0259ddd61e8341df8f3fad0e0ec81aa0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "04719cf56f8847ab986d987f9531594b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0662a1d8df34481691d184ec065aba33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a6d9016ca22947648e1468b14e2fb37f",
       "style": "IPY_MODEL_b853eed886974dab839db80b6689ba95",
       "value": " 148/148 [00:00&lt;00:00, 4248.18 examples/s]"
      }
     },
     "0919e99af3454513b9659b54448c9176": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b5acc5fd39043e5a8544b49d291403e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1124e78609da486395bd45f8eb429e74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_87bf2df1f50144ff8291634b36d7ec68",
       "max": 148,
       "style": "IPY_MODEL_d18f887c2c104629a39170216851d826",
       "value": 148
      }
     },
     "15276b25aaaf4ef3818cc1c76e27c845": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "15fd500f686f4733998c380bf6924d14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_67ba2047b1824b8990ca65d1500da8fb",
       "style": "IPY_MODEL_6a287eb8271342c486b9eb94b9b7e893",
       "value": " 504/? [11:55&lt;00:00,  2.84it/s]"
      }
     },
     "160ecfa9cd9e438faa7b0e7d3445c1bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18ffc4ab3a884097a6638933c5736650": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2067a3898a134d358c347f663fc04934": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9b51fa44bf374849b99d8ea245dff884",
       "style": "IPY_MODEL_6a1b7e31b1b340168ea6bb49df54d4eb",
       "value": "Map: 100%"
      }
     },
     "290504bb50ec454eb0ef435b13cd0b28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_70815ab44a404672a58a7a57cd29c294",
       "style": "IPY_MODEL_c794fc2345ca4e51aa04924bb71807d4",
       "value": " 1183/1183 [00:00&lt;00:00, 4055.77 examples/s]"
      }
     },
     "2bd41a0bc54341c1a7a969eea5c41a8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2d68f1a8e05e4d5abf9b12dab8853e98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2db943df180a498c9c19e2201bcebdbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2f7fcb49589e4aa89d16dcd9a3bb5a38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "326ef52d102f4ad093b9a555ede87e02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "335606bc1a9d42a7b1be6e021a1f2039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_88a9352237254f828b54a6f0f022ed97",
        "IPY_MODEL_9d078298e8c8473a976cc8abf3224226",
        "IPY_MODEL_d6862a39cfab4d3e862bdc7291b96ddd"
       ],
       "layout": "IPY_MODEL_ee546cdea14f4688a6b278e38fc7b5aa"
      }
     },
     "3397997bff94456a8e99e1a5cae84f46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "34c562c86ead48cea76bf041223b79d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3f809ae2e4624684a61f6b14f47011f4",
        "IPY_MODEL_b029c0cb60aa4e25bcb6dce71ed13d2e",
        "IPY_MODEL_290504bb50ec454eb0ef435b13cd0b28"
       ],
       "layout": "IPY_MODEL_0259ddd61e8341df8f3fad0e0ec81aa0"
      }
     },
     "38035a0f299c486398994168fac5061e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3f4a9c341fee4230a25e595e5ab09e04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2067a3898a134d358c347f663fc04934",
        "IPY_MODEL_1124e78609da486395bd45f8eb429e74",
        "IPY_MODEL_a0b62b457ed145dd841fef805ad313cb"
       ],
       "layout": "IPY_MODEL_494bfa3631334645ab4d71813b5968b8"
      }
     },
     "3f809ae2e4624684a61f6b14f47011f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6aef61a7d04c448097005d4c0a72c4ba",
       "style": "IPY_MODEL_18ffc4ab3a884097a6638933c5736650",
       "value": "Map: 100%"
      }
     },
     "40aa69f86b7c48c5a59264f0f383c72b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4389f9365b154dcf866e5a843765640e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "44ac1aa672cf456ea4efb76c104049fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "47e10a4c9e8549cd8e7c311a72775b82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b6daa38a017d4af0a83999478e1d33b8",
       "style": "IPY_MODEL_04719cf56f8847ab986d987f9531594b"
      }
     },
     "494bfa3631334645ab4d71813b5968b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4e703f08e105437c83e0ffc5f7938a1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5213bb3b778e44a18495ea5781315e77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_47e10a4c9e8549cd8e7c311a72775b82",
        "IPY_MODEL_d6395e06b96b4719b9c4505feb2632f4",
        "IPY_MODEL_15fd500f686f4733998c380bf6924d14"
       ],
       "layout": "IPY_MODEL_2d68f1a8e05e4d5abf9b12dab8853e98"
      }
     },
     "554da01982c146b29c16c657c6c2c61a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_f4253d3b723e466889058401a8019f28",
       "style": "IPY_MODEL_6e4a5e2cfe9f4a7bb64c5ea77f5011b3",
       "value": "0.024 MB of 0.024 MB uploaded\r"
      }
     },
     "5c1000df64d34f309c9777cb6ce3f9a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5ec161efed764ed8945e61ac78c239cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "62995ec06f344c7295582f30cfe953dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "63e65219cbaf4104bcfa6fc846c7c2f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b6fdfd28fa0347ee941ed69afd894aa4",
        "IPY_MODEL_b8ba7eba6ccf49e09e62893c932db35b",
        "IPY_MODEL_ade808879e9147e1a113452a9fc0624b"
       ],
       "layout": "IPY_MODEL_15276b25aaaf4ef3818cc1c76e27c845"
      }
     },
     "67ba2047b1824b8990ca65d1500da8fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6a1b7e31b1b340168ea6bb49df54d4eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6a287eb8271342c486b9eb94b9b7e893": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6aef61a7d04c448097005d4c0a72c4ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6c25f0159713408aa4c767681b9b617f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6c932552ade742d9b578f0957c88a4ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6cee8a889c404bacace6c56b618112bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_44ac1aa672cf456ea4efb76c104049fb",
       "style": "IPY_MODEL_5ec161efed764ed8945e61ac78c239cb"
      }
     },
     "6e4a5e2cfe9f4a7bb64c5ea77f5011b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "70815ab44a404672a58a7a57cd29c294": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "71091c959f624961865c14af2b7220ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7d16262243e148aa81c0b140566dd59a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d346895eec2496084f7eb9ffaf01825": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "834db6e6bcde47bbb4921d8864660d78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "87bf2df1f50144ff8291634b36d7ec68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "88a9352237254f828b54a6f0f022ed97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6c25f0159713408aa4c767681b9b617f",
       "style": "IPY_MODEL_dbb6c4981c134270a0724f924febc8fd",
       "value": "100%"
      }
     },
     "8af652d7a0b146b2ba5b982d14249c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9b51fa44bf374849b99d8ea245dff884": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9cdc251437b0484da04b3d710ddae39c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6cee8a889c404bacace6c56b618112bc",
        "IPY_MODEL_c32a3187ee354ac1a3a9d8b27eb8b7b4"
       ],
       "layout": "IPY_MODEL_2db943df180a498c9c19e2201bcebdbd"
      }
     },
     "9d078298e8c8473a976cc8abf3224226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_4e703f08e105437c83e0ffc5f7938a1a",
       "max": 3700,
       "style": "IPY_MODEL_834db6e6bcde47bbb4921d8864660d78",
       "value": 3700
      }
     },
     "a0b62b457ed145dd841fef805ad313cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c4249d6e4ce941bcafcf0f04348db2c0",
       "style": "IPY_MODEL_e87f2a920ca24f3fae3d5ce0efc9c13f",
       "value": " 148/148 [00:00&lt;00:00, 2281.76 examples/s]"
      }
     },
     "a5ac6910ac7d4823a4d361f1cfe801fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_3397997bff94456a8e99e1a5cae84f46",
       "max": 1,
       "style": "IPY_MODEL_62995ec06f344c7295582f30cfe953dc",
       "value": 1
      }
     },
     "a6d9016ca22947648e1468b14e2fb37f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ade808879e9147e1a113452a9fc0624b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b33920462942409d819cc2ed9e47e2c6",
       "style": "IPY_MODEL_7d346895eec2496084f7eb9ffaf01825",
       "value": " 1479/1479 [00:00&lt;00:00, 8364.32it/s]"
      }
     },
     "b029c0cb60aa4e25bcb6dce71ed13d2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_326ef52d102f4ad093b9a555ede87e02",
       "max": 1183,
       "style": "IPY_MODEL_38035a0f299c486398994168fac5061e",
       "value": 1183
      }
     },
     "b33920462942409d819cc2ed9e47e2c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b6daa38a017d4af0a83999478e1d33b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b6fdfd28fa0347ee941ed69afd894aa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6c932552ade742d9b578f0957c88a4ef",
       "style": "IPY_MODEL_8af652d7a0b146b2ba5b982d14249c96",
       "value": "100%"
      }
     },
     "b853eed886974dab839db80b6689ba95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b8ba7eba6ccf49e09e62893c932db35b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0b5acc5fd39043e5a8544b49d291403e",
       "max": 1479,
       "style": "IPY_MODEL_bb26a663a8304bd1bae06b88cc91c452",
       "value": 1479
      }
     },
     "bb26a663a8304bd1bae06b88cc91c452": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "befcee9c628345dca6ea6c436ec9a918": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4389f9365b154dcf866e5a843765640e",
       "style": "IPY_MODEL_d9550f8ad02c418cbb00c0bdc7dd182f",
       "value": "Map: 100%"
      }
     },
     "c32a3187ee354ac1a3a9d8b27eb8b7b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0919e99af3454513b9659b54448c9176",
       "max": 1,
       "style": "IPY_MODEL_2bd41a0bc54341c1a7a969eea5c41a8d"
      }
     },
     "c4249d6e4ce941bcafcf0f04348db2c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c794fc2345ca4e51aa04924bb71807d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d18f887c2c104629a39170216851d826": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d6395e06b96b4719b9c4505feb2632f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_febaa7cf9e1148fdbf1f1c5945c48227",
       "max": 500,
       "style": "IPY_MODEL_71091c959f624961865c14af2b7220ec",
       "value": 500
      }
     },
     "d6862a39cfab4d3e862bdc7291b96ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e7f7c55ded164f658e20786d9f5f9907",
       "style": "IPY_MODEL_7d16262243e148aa81c0b140566dd59a",
       "value": " 3700/3700 [11:54&lt;00:00,  5.30it/s]"
      }
     },
     "d9550f8ad02c418cbb00c0bdc7dd182f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dbb6c4981c134270a0724f924febc8fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dde23f17430945a7ad7cea862842c174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2f7fcb49589e4aa89d16dcd9a3bb5a38",
       "max": 148,
       "style": "IPY_MODEL_5c1000df64d34f309c9777cb6ce3f9a8",
       "value": 148
      }
     },
     "df524a34f407481fb822090ad01f0921": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_befcee9c628345dca6ea6c436ec9a918",
        "IPY_MODEL_dde23f17430945a7ad7cea862842c174",
        "IPY_MODEL_0662a1d8df34481691d184ec065aba33"
       ],
       "layout": "IPY_MODEL_40aa69f86b7c48c5a59264f0f383c72b"
      }
     },
     "e7f7c55ded164f658e20786d9f5f9907": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e87f2a920ca24f3fae3d5ce0efc9c13f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ee546cdea14f4688a6b278e38fc7b5aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4253d3b723e466889058401a8019f28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "febaa7cf9e1148fdbf1f1c5945c48227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
