{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:36.403342Z",
     "iopub.status.busy": "2024-03-01T06:28:36.403161Z",
     "iopub.status.idle": "2024-03-01T06:28:38.288916Z",
     "shell.execute_reply": "2024-03-01T06:28:38.288153Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:38.292508Z",
     "iopub.status.busy": "2024-03-01T06:28:38.292315Z",
     "iopub.status.idle": "2024-03-01T06:28:39.902373Z",
     "shell.execute_reply": "2024-03-01T06:28:39.901525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb87046b-24e4-4963-ace0-615a30c7ddeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.906349Z",
     "iopub.status.busy": "2024-03-01T06:28:39.906150Z",
     "iopub.status.idle": "2024-03-01T06:28:39.909835Z",
     "shell.execute_reply": "2024-03-01T06:28:39.909284Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'ecfp0'\n",
    "samples_count1 = '10M'\n",
    "samples_count2 = '2M'\n",
    "model_name1 = f'molberto_{filename}_{samples_count1}'\n",
    "model_name2 = f'molberto_{filename}_{samples_count2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effd7294-42cf-4de5-91d4-d6ab3fec2127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.912003Z",
     "iopub.status.busy": "2024-03-01T06:28:39.911824Z",
     "iopub.status.idle": "2024-03-01T06:28:39.914568Z",
     "shell.execute_reply": "2024-03-01T06:28:39.914150Z"
    }
   },
   "outputs": [],
   "source": [
    "# molecular_properties = ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.916824Z",
     "iopub.status.busy": "2024-03-01T06:28:39.916653Z",
     "iopub.status.idle": "2024-03-01T06:28:39.936712Z",
     "shell.execute_reply": "2024-03-01T06:28:39.936027Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"clintox-1k-ecfp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.939358Z",
     "iopub.status.busy": "2024-03-01T06:28:39.939185Z",
     "iopub.status.idle": "2024-03-01T06:28:39.941856Z",
     "shell.execute_reply": "2024-03-01T06:28:39.941441Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataframe = dataframe.drop(columns=['Unnamed: 0', 'Smiles', 'ecfp2', 'ecfp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.944003Z",
     "iopub.status.busy": "2024-03-01T06:28:39.943835Z",
     "iopub.status.idle": "2024-03-01T06:28:39.947222Z",
     "shell.execute_reply": "2024-03-01T06:28:39.946647Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints[0])\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:39.949342Z",
     "iopub.status.busy": "2024-03-01T06:28:39.949172Z",
     "iopub.status.idle": "2024-03-01T06:28:40.166384Z",
     "shell.execute_reply": "2024-03-01T06:28:40.165680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbb1be93c91474c820ff2a3b98fb813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9f902e-7691-4256-883a-bd70f484a5c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.169829Z",
     "iopub.status.busy": "2024-03-01T06:28:40.169649Z",
     "iopub.status.idle": "2024-03-01T06:28:40.180430Z",
     "shell.execute_reply": "2024-03-01T06:28:40.179846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)OC(=O)CCC/C=C\\C[C@@H]1[C@@H](CC[C@@H](O)C...</td>\n",
       "      <td>2246728737 2245273601 2246728737 864674487 224...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(O)C(CO)NC(=O)C1CSSCC(NC(=O)C([NH3+])Cc2cccc...</td>\n",
       "      <td>2246728737 2245273601 864662311 2245273601 224...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(c1cc2ccccc2s1)N(O)C(N)=O</td>\n",
       "      <td>2246728737 2245273601 3217380708 3218693969 32...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C(=O)[O-])c1ccc(C(=O)c2cccs2)cc1</td>\n",
       "      <td>2246728737 2245273601 2246699815 864942730 864...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C[NH2+]C1CCCCC1)OC(=O)c1ccccc1</td>\n",
       "      <td>2246728737 2245273601 2245384272 847690172 297...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>NS(=O)(=O)c1cc(Cl)c(Cl)c(S(N)(=O)=O)c1</td>\n",
       "      <td>847957139 999334238 864942730 864942730 321738...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>N#Cc1cc(NC(=O)C(=O)[O-])c(Cl)c(NC(=O)C(=O)[O-])c1</td>\n",
       "      <td>847433064 2245900962 3217380708 3218693969 321...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Clc1cc(Cl)c(OCC#CI)cc1Cl</td>\n",
       "      <td>1016841875 3217380708 3218693969 3217380708 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>O=C(NCC(O)CO)c1c(I)c(C(=O)NCC(O)CO)c(I)c(N(CCO...</td>\n",
       "      <td>864942730 2246699815 847961216 2245384272 2245...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>CC(C)C[C@H](NC(=O)CNC(=O)c1cc(Cl)ccc1Cl)B(O)O</td>\n",
       "      <td>2246728737 2245273601 2246728737 2245384272 22...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles  \\\n",
       "0     CC(C)OC(=O)CCC/C=C\\C[C@@H]1[C@@H](CC[C@@H](O)C...   \n",
       "1     CC(O)C(CO)NC(=O)C1CSSCC(NC(=O)C([NH3+])Cc2cccc...   \n",
       "2                           CC(c1cc2ccccc2s1)N(O)C(N)=O   \n",
       "3                   CC(C(=O)[O-])c1ccc(C(=O)c2cccs2)cc1   \n",
       "4                     CC(C[NH2+]C1CCCCC1)OC(=O)c1ccccc1   \n",
       "...                                                 ...   \n",
       "1163             NS(=O)(=O)c1cc(Cl)c(Cl)c(S(N)(=O)=O)c1   \n",
       "1164  N#Cc1cc(NC(=O)C(=O)[O-])c(Cl)c(NC(=O)C(=O)[O-])c1   \n",
       "1165                           Clc1cc(Cl)c(OCC#CI)cc1Cl   \n",
       "1166  O=C(NCC(O)CO)c1c(I)c(C(=O)NCC(O)CO)c(I)c(N(CCO...   \n",
       "1167      CC(C)C[C@H](NC(=O)CNC(=O)c1cc(Cl)ccc1Cl)B(O)O   \n",
       "\n",
       "                                                   ecfp  target  \n",
       "0     2246728737 2245273601 2246728737 864674487 224...       0  \n",
       "1     2246728737 2245273601 864662311 2245273601 224...       0  \n",
       "2     2246728737 2245273601 3217380708 3218693969 32...       0  \n",
       "3     2246728737 2245273601 2246699815 864942730 864...       0  \n",
       "4     2246728737 2245273601 2245384272 847690172 297...       0  \n",
       "...                                                 ...     ...  \n",
       "1163  847957139 999334238 864942730 864942730 321738...       0  \n",
       "1164  847433064 2245900962 3217380708 3218693969 321...       0  \n",
       "1165  1016841875 3217380708 3218693969 3217380708 10...       0  \n",
       "1166  864942730 2246699815 847961216 2245384272 2245...       0  \n",
       "1167  2246728737 2245273601 2246728737 2245384272 22...       1  \n",
       "\n",
       "[1168 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628bf71f-7af4-4eab-9fa2-e1bec5c7d682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.182658Z",
     "iopub.status.busy": "2024-03-01T06:28:40.182473Z",
     "iopub.status.idle": "2024-03-01T06:28:40.185650Z",
     "shell.execute_reply": "2024-03-01T06:28:40.185044Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('Percentage on NaNs:')\n",
    "# dataframe.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9131af22-72dd-4fee-b5b4-9a5b159030cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.188387Z",
     "iopub.status.busy": "2024-03-01T06:28:40.188114Z",
     "iopub.status.idle": "2024-03-01T06:28:40.191198Z",
     "shell.execute_reply": "2024-03-01T06:28:40.190673Z"
    }
   },
   "outputs": [],
   "source": [
    "# rows_with_nans = dataframe['Molecular Weight'].isna() | \\\n",
    "#                  dataframe['Bioactivities'].isna() | \\\n",
    "#                  dataframe['AlogP'].isna() | \\\n",
    "#                  dataframe['Polar Surface Area'].isna() | \\\n",
    "#                  dataframe['CX Acidic pKa'].isna() | \\\n",
    "#                  dataframe['CX Basic pKa'].isna()\n",
    "# print(f'Count of rows without NaNs: {dataframe.shape[0] - dataframe.loc[rows_with_nans].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeec7baa-b6bb-47a1-bf4a-66e94049750f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.193660Z",
     "iopub.status.busy": "2024-03-01T06:28:40.193499Z",
     "iopub.status.idle": "2024-03-01T06:28:40.196095Z",
     "shell.execute_reply": "2024-03-01T06:28:40.195480Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove 2 last properties to reduce NaN counts\n",
    "# molecular_properties = ['Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area']\n",
    "# dataframe = dataframe.drop(columns=['CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1964f7f1-2efc-4333-81bc-3ebbdcbec934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.198216Z",
     "iopub.status.busy": "2024-03-01T06:28:40.198049Z",
     "iopub.status.idle": "2024-03-01T06:28:40.200389Z",
     "shell.execute_reply": "2024-03-01T06:28:40.199877Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop NaN's\n",
    "# dataframe = dataframe.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b3b5a83-5050-48d4-8813-490c01fbc1e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.202511Z",
     "iopub.status.busy": "2024-03-01T06:28:40.202348Z",
     "iopub.status.idle": "2024-03-01T06:28:40.204742Z",
     "shell.execute_reply": "2024-03-01T06:28:40.204337Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e96ad73-2190-48f4-a1c3-ba4b5325f62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.206770Z",
     "iopub.status.busy": "2024-03-01T06:28:40.206607Z",
     "iopub.status.idle": "2024-03-01T06:28:40.580416Z",
     "shell.execute_reply": "2024-03-01T06:28:40.579565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target'],\n",
       "        num_rows: 934\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=15)\n",
    "\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=15)\n",
    "\n",
    "# 10% for test, 10 for validation, 80% for train\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'validation': test_valid['train']})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f3e06-7933-457f-a51d-0373c34f413a",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7720fb53-0a36-452f-8d5a-f23f0c5755d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.583136Z",
     "iopub.status.busy": "2024-03-01T06:28:40.582846Z",
     "iopub.status.idle": "2024-03-01T06:28:40.714567Z",
     "shell.execute_reply": "2024-03-01T06:28:40.713664Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "tokenizer.model_max_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f924833-477c-4a24-936e-d62f0ca5dd8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:40.717128Z",
     "iopub.status.busy": "2024-03-01T06:28:40.716902Z",
     "iopub.status.idle": "2024-03-01T06:28:41.028410Z",
     "shell.execute_reply": "2024-03-01T06:28:41.027688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e3554f75264c69ad2edfeeafd7a016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717b5e7306f746148d439f0c1f916383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37737f372d2f4822ab401a4a0275d49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 934\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Smiles', 'ecfp', 'target', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"ecfp\"], truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "434caf18-e9b1-42ac-b40e-05c1b75c538a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:41.030711Z",
     "iopub.status.busy": "2024-03-01T06:28:41.030530Z",
     "iopub.status.idle": "2024-03-01T06:28:42.950580Z",
     "shell.execute_reply": "2024-03-01T06:28:42.949814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'target']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 09:28:41.434070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "columns = [\"input_ids\", \"attention_mask\"]\n",
    "columns.extend(['target']) # our labels\n",
    "print(columns)\n",
    "tokenized_dataset.set_format('torch', columns=columns)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:42.954003Z",
     "iopub.status.busy": "2024-03-01T06:28:42.953566Z",
     "iopub.status.idle": "2024-03-01T06:28:42.966074Z",
     "shell.execute_reply": "2024-03-01T06:28:42.965531Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class MolecularPropertiesClassification(torch.nn.Module):\n",
    "    def __init__(self, model_name1, model_name2):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "\n",
    "        config1 = AutoConfig.from_pretrained(model_name1)\n",
    "        self.transformer1 = AutoModel.from_pretrained(model_name1, config=config1)\n",
    "        # removing last layer of transformer\n",
    "        self.transformer1.pooler = torch.nn.Identity()\n",
    "        # freezing transformer weights\n",
    "        for param in self.transformer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # config2 = AutoConfig.from_pretrained(model_name2)\n",
    "        # self.transformer2 = AutoModel.from_pretrained(model_name2, config=config2)\n",
    "        # # removing last layer of transformer\n",
    "        # self.transformer2.pooler = torch.nn.Identity()\n",
    "        # # freezing transformer weights\n",
    "        # for param in self.transformer2.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(768, 2, bias=True)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs1 = self.transformer1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # outputs2 = self.transformer2(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state1 = outputs1[0]\n",
    "        # last_hidden_state2 = outputs2[0]\n",
    "        \n",
    "        first_linear_out = self.linear1(last_hidden_state1[:, 0, : ].view(-1, 768))\n",
    "        logits = self.linear2(torch.nn.functional.sigmoid(first_linear_out))\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:42.968808Z",
     "iopub.status.busy": "2024-03-01T06:28:42.968631Z",
     "iopub.status.idle": "2024-03-01T06:28:42.972468Z",
     "shell.execute_reply": "2024-03-01T06:28:42.971851Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:42.974508Z",
     "iopub.status.busy": "2024-03-01T06:28:42.974344Z",
     "iopub.status.idle": "2024-03-01T06:28:45.791430Z",
     "shell.execute_reply": "2024-03-01T06:28:45.790394Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/test/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at molberto_ecfp0_2M and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\", index=4) if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = MolecularPropertiesClassification(model_name1, model_name2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:45.794963Z",
     "iopub.status.busy": "2024-03-01T06:28:45.794729Z",
     "iopub.status.idle": "2024-03-01T06:28:45.801152Z",
     "shell.execute_reply": "2024-03-01T06:28:45.800692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularPropertiesClassification(\n",
       "  (transformer1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Identity()\n",
       "  )\n",
       "  (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:45.803304Z",
     "iopub.status.busy": "2024-03-01T06:28:45.803131Z",
     "iopub.status.idle": "2024-03-01T06:28:46.304402Z",
     "shell.execute_reply": "2024-03-01T06:28:46.303759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyorlov53/anaconda3/envs/test/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:46.308971Z",
     "iopub.status.busy": "2024-03-01T06:28:46.307923Z",
     "iopub.status.idle": "2024-03-01T06:28:52.233318Z",
     "shell.execute_reply": "2024-03-01T06:28:52.232633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33morlov-aleksei53\u001b[0m (\u001b[33mmoleculary-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/alexeyorlov53/Transformers-for-Molecules/wandb/run-20240301_092847-awjcvpc5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mSingleTransformer with LinearClassifier clintox training \u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/moleculary-ai/efcp_transformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/moleculary-ai/efcp_transformer/runs/awjcvpc5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/moleculary-ai/efcp_transformer/runs/awjcvpc5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f34f0ea98d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"SingleTransformer with LinearClassifier clintox training \",\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:28:52.236316Z",
     "iopub.status.busy": "2024-03-01T06:28:52.236131Z",
     "iopub.status.idle": "2024-03-01T06:39:38.147093Z",
     "shell.execute_reply": "2024-03-01T06:39:38.146199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b79c40a18419abe6a9b4602c109e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e467008afd45319998932aae5e2db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/train\": epoch_loss / len(train_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/train\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/train\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/train\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/train\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch['target']\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:39:38.151515Z",
     "iopub.status.busy": "2024-03-01T06:39:38.151311Z",
     "iopub.status.idle": "2024-03-01T06:39:53.196903Z",
     "shell.execute_reply": "2024-03-01T06:39:53.195877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy/train ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  accuracy/validation ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             f1/train ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        f1/validation ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss/train █▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      loss/validation ▇▅▁▂▄▂▄▄▃▄▂▁▁▂▂▇▃█▄▂▂▃▁▅▇▁▇▅▅▇▆▄▂▆▄▂▅▁▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      precision/train ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: precision/validation ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         recall/train ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    recall/validation ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy/train 0.93041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  accuracy/validation 0.93162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             f1/train 0.93041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        f1/validation 0.93162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss/train 0.21583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      loss/validation 0.24931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      precision/train 0.93041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: precision/validation 0.93162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         recall/train 0.93041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    recall/validation 0.93162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mSingleTransformer with LinearClassifier clintox training \u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/moleculary-ai/efcp_transformer/runs/awjcvpc5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240301_092847-awjcvpc5/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T06:39:53.200121Z",
     "iopub.status.busy": "2024-03-01T06:39:53.199942Z",
     "iopub.status.idle": "2024-03-01T06:39:53.219121Z",
     "shell.execute_reply": "2024-03-01T06:39:53.218466Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
