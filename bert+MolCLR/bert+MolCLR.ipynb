{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19af74bd-8f87-44d5-ada6-2bcbdcee1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", index=4) if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['ecfp2', 'ecfp3', 'Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ce4a4d-2911-4103-aca3-40843f0745e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...</td>\n",
       "      <td>['2246728737', '864674487', '3217380708', '321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...</td>\n",
       "      <td>['2246728737', '864674487', '2246699815', '864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...</td>\n",
       "      <td>['2246728737', '2245384272', '2976033787', '31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...</td>\n",
       "      <td>['2246728737', '3217380708', '3218693969', '32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...</td>\n",
       "      <td>['2246728737', '2245384272', '864674487', '224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CCN1CCN(CC(O)c2ccc(Br)cc2)CC1</td>\n",
       "      <td>['2246728737', '2245384272', '2092489639', '29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1</td>\n",
       "      <td>['864942730', '2246699815', '864662311', '2245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...</td>\n",
       "      <td>['864942730', '2246699815', '847961216', '2976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1</td>\n",
       "      <td>['2246728737', '2245384272', '864674487', '321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1</td>\n",
       "      <td>['2246703798', '847336149', '847961216', '3217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles  \\\n",
       "0     COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...   \n",
       "1     COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...   \n",
       "2     CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...   \n",
       "3     Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...   \n",
       "4     CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...   \n",
       "...                                                 ...   \n",
       "9995                      CCN1CCN(CC(O)c2ccc(Br)cc2)CC1   \n",
       "9996         O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1   \n",
       "9997  O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...   \n",
       "9998          CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1   \n",
       "9999                    C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1   \n",
       "\n",
       "                                                  ecfp1  \n",
       "0     ['2246728737', '864674487', '3217380708', '321...  \n",
       "1     ['2246728737', '864674487', '2246699815', '864...  \n",
       "2     ['2246728737', '2245384272', '2976033787', '31...  \n",
       "3     ['2246728737', '3217380708', '3218693969', '32...  \n",
       "4     ['2246728737', '2245384272', '864674487', '224...  \n",
       "...                                                 ...  \n",
       "9995  ['2246728737', '2245384272', '2092489639', '29...  \n",
       "9996  ['864942730', '2246699815', '864662311', '2245...  \n",
       "9997  ['864942730', '2246699815', '847961216', '2976...  \n",
       "9998  ['2246728737', '2245384272', '864674487', '321...  \n",
       "9999  ['2246703798', '847336149', '847961216', '3217...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this because pandas thinks columns with arrays are strings\n",
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints[0])\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666b76087a114e69bb33327e7063e00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae984aa-919e-438b-82bf-76747ac879c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8d0d1-a614-4d8b-958a-ec563f66db70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58e8c4-b226-4247-9ddf-8f69df72376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "def CustomDataCollator():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5d0bdc0-89c4-494d-a76a-5cc7071cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MolCLR.dataset.dataset import MoleculeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4337128b-a31d-44fc-82f2-6e208f519fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDatasetWrapper(object):\n",
    "    def __init__(self, batch_size, num_workers, valid_size, data, tokenizer_name):\n",
    "        super(object, self).__init__()\n",
    "        \n",
    "        tokenized_dataset = dataset.map(self.tokenize, batched=True)\n",
    "        columns = [\"input_ids\", \"attention_mask\"]\n",
    "        columns.extend(['target']) # our labels\n",
    "        tokenized_dataset.set_format('torch', columns=columns)\n",
    "        \n",
    "        self.data = tokenized_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.valid_size = valid_size\n",
    "        \n",
    "        from transformers import AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer.model_max_len = 512\n",
    "\n",
    "    def tokenize(self, batch):\n",
    "        return self.tokenizer(batch[\"ecfp1\"], truncation=True, max_length=512, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453e2341-7a45-4a2e-bf01-588dcd72fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ececf3c-f3f7-4220-a292-bf16b702c463",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m molclr_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMoleculeDatasetWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmolberto_ecfp0_2M\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Transformers-for-Molecules/bert+MolCLR/MolCLR/dataset/dataset.py:163\u001b[0m, in \u001b[0;36mMoleculeDatasetWrapper.__init__\u001b[0;34m(self, batch_size, num_workers, valid_size, data, tokenizer_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size, num_workers, valid_size, data, tokenizer_name):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28msuper\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 163\u001b[0m     tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    164\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    165\u001b[0m     columns\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# our labels\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "molclr_dataset = MoleculeDatasetWrapper(data=dataframe, batch_size=64, num_workers=8, valid_size=0.2, tokenizer_name='molberto_ecfp0_2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8505f-c94d-4fe0-9097-18790d12f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = self.dataset.get_data_loaders()\n",
    "\n",
    "if self.config['model_type'] == 'gin':\n",
    "    from models.ginet_molclr import GINet\n",
    "    model = GINet(**self.config[\"model\"]).to(self.device)\n",
    "    model = self._load_pre_trained_weights(model)\n",
    "elif self.config['model_type'] == 'gcn':\n",
    "    from models.gcn_molclr import GCN\n",
    "    model = GCN(**self.config[\"model\"]).to(self.device)\n",
    "    model = self._load_pre_trained_weights(model)\n",
    "else:\n",
    "    raise ValueError('Undefined GNN model.')\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), self.config['init_lr'], \n",
    "    weight_decay=eval(self.config['weight_decay'])\n",
    ")\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, T_max=self.config['epochs']-self.config['warm_up'], \n",
    "    eta_min=0, last_epoch=-1\n",
    ")\n",
    "\n",
    "if apex_support and self.config['fp16_precision']:\n",
    "    model, optimizer = amp.initialize(\n",
    "        model, optimizer, opt_level='O2', keep_batchnorm_fp32=True\n",
    "    )\n",
    "\n",
    "model_checkpoints_folder = os.path.join(self.writer.log_dir, 'checkpoints')\n",
    "\n",
    "# save config file\n",
    "_save_config_file(model_checkpoints_folder)\n",
    "\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch_counter in range(self.config['epochs']):\n",
    "    for bn, (xis, xjs) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xis = xis.to(self.device)\n",
    "        xjs = xjs.to(self.device)\n",
    "\n",
    "        loss = self._step(model, xis, xjs, n_iter)\n",
    "\n",
    "        if n_iter % self.config['log_every_n_steps'] == 0:\n",
    "            self.writer.add_scalar('train_loss', loss, global_step=n_iter)\n",
    "            self.writer.add_scalar('cosine_lr_decay', scheduler.get_last_lr()[0], global_step=n_iter)\n",
    "            print(epoch_counter, bn, loss.item())\n",
    "\n",
    "        if apex_support and self.config['fp16_precision']:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "\n",
    "    # validate the model if requested\n",
    "    if epoch_counter % self.config['eval_every_n_epochs'] == 0:\n",
    "        valid_loss = self._validate(model, valid_loader)\n",
    "        print(epoch_counter, bn, valid_loss, '(validation)')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            # save the model weights\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "    \n",
    "        self.writer.add_scalar('validation_loss', valid_loss, global_step=valid_n_iter)\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    if (epoch_counter+1) % self.config['save_every_n_epochs'] == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model_{}.pth'.format(str(epoch_counter))))\n",
    "\n",
    "    # warmup for the first few epochs\n",
    "    if epoch_counter >= self.config['warm_up']:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "from MolCLR.models.gcn_molclr import GCN\n",
    "from MolCLR.molclr import MolCLR\n",
    "\n",
    "class MolecularDoubleApproach(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "\n",
    "        config = RobertaConfig(\n",
    "            vocab_size=30_522,  # we align this to the tokenizer vocab set in previous notebook\n",
    "            max_position_embeddings=514,\n",
    "            hidden_size=768,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1\n",
    "        )\n",
    "        self.model1 = RobertaForMaskedLM(config)\n",
    "        # removing last layer of transformer\n",
    "        self.model1.pooler = torch.nn.Identity()\n",
    "        \n",
    "        self.model2 = GCN(**config[\"model\"]).to(self.device)\n",
    "        self.model2 = self._load_pre_trained_weights(model)\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768 * 2, 768, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(768, 2, bias=True)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs1 = self.model1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs2 = MolCLR._step(self.model2, xis, xjs)\n",
    "        last_hidden_state1 = outputs1[0]\n",
    "        last_hidden_state2 = outputs2[0]\n",
    "        \n",
    "        first_linear_out = self.linear1( \\\n",
    "            torch.cat((last_hidden_state1[:, 0, : ], last_hidden_state2[:, 0, : ]), dim=-1).view(-1, 2 * 768))\n",
    "        logits = self.linear2(torch.nn.functional.sigmoid(first_linear_out))\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolecularDoubleApproach().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"RobertaForMaskedLM + MolCLR (GCN)\",\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/train\": epoch_loss / len(train_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/train\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/train\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/train\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/train\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch['target']\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607de5a0-ec7b-490c-b188-4ef0ad28b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "total_pred_labels = []\n",
    "total_true_labels = []\n",
    "epoch_loss = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "    batch['target'] = batch['target'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**input_batch)\n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "\n",
    "total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "\n",
    "wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "029db7587ec14fab8eb1b11fb0bc47cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2e5b9dd51f154f97821f821d3d05e38d",
       "style": "IPY_MODEL_7d32cb53d23549a3866bb35eca080ba1",
       "value": "100%"
      }
     },
     "2e5b9dd51f154f97821f821d3d05e38d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "666b76087a114e69bb33327e7063e00d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_029db7587ec14fab8eb1b11fb0bc47cd",
        "IPY_MODEL_85ba1e3a4ad64e83821980df6345c7c7",
        "IPY_MODEL_a6b1bbe3f3ba4f3ead3e3a93dd2491e3"
       ],
       "layout": "IPY_MODEL_ba7af72af5d940d9ad87c720e6f4ba4a"
      }
     },
     "7d32cb53d23549a3866bb35eca080ba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "801823505b894380b5c75f2c09a73169": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85ba1e3a4ad64e83821980df6345c7c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e27ee8fe5d10423eb701465c6a990cf0",
       "max": 10000,
       "style": "IPY_MODEL_97ef6d532cd34bc6892833a80859a28a",
       "value": 10000
      }
     },
     "97ef6d532cd34bc6892833a80859a28a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a6b1bbe3f3ba4f3ead3e3a93dd2491e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4320889897247a2b088960f6500ceed",
       "style": "IPY_MODEL_801823505b894380b5c75f2c09a73169",
       "value": " 10000/10000 [00:00&lt;00:00, 11663.25it/s]"
      }
     },
     "ba7af72af5d940d9ad87c720e6f4ba4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e27ee8fe5d10423eb701465c6a990cf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4320889897247a2b088960f6500ceed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
