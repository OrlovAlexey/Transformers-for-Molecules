{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19af74bd-8f87-44d5-ada6-2bcbdcee1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", index=4) if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67fa0b23-8846-4a44-96c3-cc0b9a9d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_bert = 'molberto_ecfp0_2M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['ecfp2', 'ecfp3', 'Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97ce4a4d-2911-4103-aca3-40843f0745e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...</td>\n",
       "      <td>2246728737 864674487 3217380708 3218693969 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...</td>\n",
       "      <td>2246728737 864674487 2246699815 864942730 3217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...</td>\n",
       "      <td>2246728737 2245384272 2976033787 3189457552 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...</td>\n",
       "      <td>2246728737 3217380708 3218693969 3218693969 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...</td>\n",
       "      <td>2246728737 2245384272 864674487 2246699815 864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CCN1CCN(CC(O)c2ccc(Br)cc2)CC1</td>\n",
       "      <td>2246728737 2245384272 2092489639 2968968094 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1</td>\n",
       "      <td>864942730 2246699815 864662311 2245384272 8479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...</td>\n",
       "      <td>864942730 2246699815 847961216 2976816164 2968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1</td>\n",
       "      <td>2246728737 2245384272 864674487 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1</td>\n",
       "      <td>2246703798 847336149 847961216 3217380708 2041...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles  \\\n",
       "0     COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...   \n",
       "1     COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...   \n",
       "2     CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...   \n",
       "3     Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...   \n",
       "4     CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...   \n",
       "...                                                 ...   \n",
       "9995                      CCN1CCN(CC(O)c2ccc(Br)cc2)CC1   \n",
       "9996         O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1   \n",
       "9997  O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...   \n",
       "9998          CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1   \n",
       "9999                    C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1   \n",
       "\n",
       "                                                  ecfp1  \n",
       "0     2246728737 864674487 3217380708 3218693969 321...  \n",
       "1     2246728737 864674487 2246699815 864942730 3217...  \n",
       "2     2246728737 2245384272 2976033787 3189457552 32...  \n",
       "3     2246728737 3217380708 3218693969 3218693969 32...  \n",
       "4     2246728737 2245384272 864674487 2246699815 864...  \n",
       "...                                                 ...  \n",
       "9995  2246728737 2245384272 2092489639 2968968094 29...  \n",
       "9996  864942730 2246699815 864662311 2245384272 8479...  \n",
       "9997  864942730 2246699815 847961216 2976816164 2968...  \n",
       "9998  2246728737 2245384272 864674487 3217380708 321...  \n",
       "9999  2246703798 847336149 847961216 3217380708 2041...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this because pandas thinks columns with arrays are strings\n",
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411d7d88be1d4963899e7ae67b03e045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae984aa-919e-438b-82bf-76747ac879c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8d0d1-a614-4d8b-958a-ec563f66db70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58e8c4-b226-4247-9ddf-8f69df72376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "def CustomDataCollator():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c61aaf7e-b46e-42f0-8981-67d2006f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [\n",
    "    Chem.rdchem.BondType.SINGLE, \n",
    "    Chem.rdchem.BondType.DOUBLE, \n",
    "    Chem.rdchem.BondType.TRIPLE, \n",
    "    Chem.rdchem.BondType.AROMATIC\n",
    "]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5d0bdc0-89c4-494d-a76a-5cc7071cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataset: pd.DataFrame, tokenizer, node_mask_percent=0.25, edge_mask_percent=0.25):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.node_mask_percent = node_mask_percent\n",
    "        self.edge_mask_percent = edge_mask_percent\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.model_max_len = 512\n",
    "\n",
    "    def get_graph_from_smiles(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return torch.tensor([[], []], dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    0\n",
    "    \n",
    "        N = mol.GetNumAtoms()\n",
    "        M = mol.GetNumBonds()\n",
    "    \n",
    "        type_idx = []\n",
    "        chirality_idx = []\n",
    "        atomic_number = []\n",
    "        \n",
    "        for atom in mol.GetAtoms():\n",
    "            type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "            chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "            atomic_number.append(atom.GetAtomicNum())\n",
    "        \n",
    "        x1 = torch.tensor(type_idx, dtype=torch.long).view(-1,1)\n",
    "        x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1,1)\n",
    "        node_feat = torch.cat([x1, x2], dim=-1)\n",
    "    \n",
    "        row, col, edge_feat = [], [], []\n",
    "        for bond in mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            row += [start, end]\n",
    "            col += [end, start]\n",
    "            \n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "    \n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_feat, dtype=torch.long)\n",
    "        num_nodes = N\n",
    "        num_edges = M\n",
    "    \n",
    "        return node_feat, edge_index, edge_attr, num_nodes, num_edges\n",
    "\n",
    "    def get_augmented_graph_copy(self, node_feat, edge_index, edge_attr, N, M):\n",
    "        num_mask_nodes = max([1, math.floor(self.node_mask_percent * N)])\n",
    "        num_mask_edges = max([0, math.floor(self.edge_mask_percent * M)])\n",
    "        \n",
    "        mask_nodes = random.sample(list(range(N)), num_mask_nodes)\n",
    "        mask_edges_single = random.sample(list(range(M)), num_mask_edges)\n",
    "        mask_edges = [2*i for i in mask_edges_single] + [2*i+1 for i in mask_edges_single]\n",
    "\n",
    "        node_feat_new = deepcopy(node_feat)\n",
    "        for atom_idx in mask_nodes:\n",
    "            node_feat_new[atom_idx, :] = torch.tensor([len(ATOM_LIST), 0])\n",
    "        edge_index_new = torch.zeros((2, 2*(M - num_mask_edges)), dtype=torch.long)\n",
    "        edge_attr_new = torch.zeros((2*(M - num_mask_edges), 2), dtype=torch.long)\n",
    "        count = 0\n",
    "        for bond_idx in range(2*M):\n",
    "            if bond_idx not in mask_edges:\n",
    "                edge_index_new[:, count] = edge_index[:, bond_idx]\n",
    "                edge_attr_new[count, :] = edge_attr[bond_idx, :]\n",
    "                count += 1\n",
    "        return Data(x=node_feat_new, edge_index=edge_index_new, edge_attr=edge_attr_new)\n",
    "\n",
    "    def tokenize(self, item):\n",
    "        return self.tokenizer(item, truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "    def mlm(self, tensor):\n",
    "        rand = torch.rand(tensor.shape)\n",
    "        # mask random 15% where token is not 0 <s>, 1 <pad>, or 2 <s/>\n",
    "        mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "        selection = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "        # mask tensor, token == 4 is our mask token\n",
    "        tensor[selection] = 4\n",
    "        return tensor\n",
    "\n",
    "    def apply_mlm(self, sample):\n",
    "        labels = torch.tensor(sample.input_ids)\n",
    "        mask = torch.tensor(sample.attention_mask)\n",
    "        input_ids = self.mlm(labels.detach().clone())\n",
    "        return Data(labels=labels, mask=mask, input_ids=input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        node_feat, edge_index, edge_attr, num_nodes, num_edges = self.get_graph_from_smiles(self.dataset['Smiles'][index])\n",
    "\n",
    "        data_i = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "        data_j = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "\n",
    "        ecfp = self.dataset['ecfp1'][index]\n",
    "        data_for_bert = self.apply_mlm(self.tokenize(ecfp))\n",
    "        return data_for_bert, data_i, data_j\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "990d0346-4204-4edd-a947-de80e85a685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_bert)\n",
    "dataset = MoleculeDataset(dataframe, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b626be9b-b785-43e9-ab25-4509613cccc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef882144-9701-4c8e-b169-0e11113172b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4d1a3-725a-49d1-8905-f4755cd07bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4337128b-a31d-44fc-82f2-6e208f519fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDatasetWrapper(object):\n",
    "    def __init__(self, batch_size, num_workers, valid_size, data, tokenizer_name):\n",
    "        super(object, self).__init__()\n",
    "        \n",
    "        tokenized_dataset = dataset.map(self.tokenize, batched=True)\n",
    "        columns = [\"input_ids\", \"attention_mask\"]\n",
    "        columns.extend(['target']) # our labels\n",
    "        tokenized_dataset.set_format('torch', columns=columns)\n",
    "        \n",
    "        self.data = tokenized_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.valid_size = valid_size\n",
    "        \n",
    "        \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453e2341-7a45-4a2e-bf01-588dcd72fd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ececf3c-f3f7-4220-a292-bf16b702c463",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m molclr_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMoleculeDatasetWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmolberto_ecfp0_2M\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Transformers-for-Molecules/bert+MolCLR/MolCLR/dataset/dataset.py:163\u001b[0m, in \u001b[0;36mMoleculeDatasetWrapper.__init__\u001b[0;34m(self, batch_size, num_workers, valid_size, data, tokenizer_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size, num_workers, valid_size, data, tokenizer_name):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28msuper\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 163\u001b[0m     tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    164\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    165\u001b[0m     columns\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# our labels\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "molclr_dataset = MoleculeDatasetWrapper(data=dataframe, batch_size=64, num_workers=8, valid_size=0.2, tokenizer_name='molberto_ecfp0_2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8505f-c94d-4fe0-9097-18790d12f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = self.dataset.get_data_loaders()\n",
    "\n",
    "if self.config['model_type'] == 'gin':\n",
    "    from models.ginet_molclr import GINet\n",
    "    model = GINet(**self.config[\"model\"]).to(self.device)\n",
    "    model = self._load_pre_trained_weights(model)\n",
    "elif self.config['model_type'] == 'gcn':\n",
    "    from models.gcn_molclr import GCN\n",
    "    model = GCN(**self.config[\"model\"]).to(self.device)\n",
    "    model = self._load_pre_trained_weights(model)\n",
    "else:\n",
    "    raise ValueError('Undefined GNN model.')\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), self.config['init_lr'], \n",
    "    weight_decay=eval(self.config['weight_decay'])\n",
    ")\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, T_max=self.config['epochs']-self.config['warm_up'], \n",
    "    eta_min=0, last_epoch=-1\n",
    ")\n",
    "\n",
    "if apex_support and self.config['fp16_precision']:\n",
    "    model, optimizer = amp.initialize(\n",
    "        model, optimizer, opt_level='O2', keep_batchnorm_fp32=True\n",
    "    )\n",
    "\n",
    "model_checkpoints_folder = os.path.join(self.writer.log_dir, 'checkpoints')\n",
    "\n",
    "# save config file\n",
    "_save_config_file(model_checkpoints_folder)\n",
    "\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch_counter in range(self.config['epochs']):\n",
    "    for bn, (xis, xjs) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xis = xis.to(self.device)\n",
    "        xjs = xjs.to(self.device)\n",
    "\n",
    "        loss = self._step(model, xis, xjs, n_iter)\n",
    "\n",
    "        if n_iter % self.config['log_every_n_steps'] == 0:\n",
    "            self.writer.add_scalar('train_loss', loss, global_step=n_iter)\n",
    "            self.writer.add_scalar('cosine_lr_decay', scheduler.get_last_lr()[0], global_step=n_iter)\n",
    "            print(epoch_counter, bn, loss.item())\n",
    "\n",
    "        if apex_support and self.config['fp16_precision']:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "\n",
    "    # validate the model if requested\n",
    "    if epoch_counter % self.config['eval_every_n_epochs'] == 0:\n",
    "        valid_loss = self._validate(model, valid_loader)\n",
    "        print(epoch_counter, bn, valid_loss, '(validation)')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            # save the model weights\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "    \n",
    "        self.writer.add_scalar('validation_loss', valid_loss, global_step=valid_n_iter)\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    if (epoch_counter+1) % self.config['save_every_n_epochs'] == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model_{}.pth'.format(str(epoch_counter))))\n",
    "\n",
    "    # warmup for the first few epochs\n",
    "    if epoch_counter >= self.config['warm_up']:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "from MolCLR.models.gcn_molclr import GCN\n",
    "from MolCLR.molclr import MolCLR\n",
    "\n",
    "class MolecularBertGraph(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "\n",
    "        config = RobertaConfig(\n",
    "            vocab_size=30_522,  # we align this to the tokenizer vocab set in previous notebook\n",
    "            max_position_embeddings=514,\n",
    "            hidden_size=768,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1\n",
    "        )\n",
    "        self.model1 = RobertaForMaskedLM(config)\n",
    "        # removing last layer of transformer\n",
    "        self.model1.pooler = torch.nn.Identity()\n",
    "        \n",
    "        self.model2 = GCN(**config[\"model\"]).to(self.device)\n",
    "        self.model2 = self._load_pre_trained_weights(model)\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768 * 2, 768, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(768, 2, bias=True)\n",
    "\n",
    "    def forward(self, input_ids = None, attention_mask=None):\n",
    "        outputs1 = self.model1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs2 = MolCLR._step(self.model2, xis, xjs)\n",
    "        last_hidden_state1 = outputs1[0]\n",
    "        last_hidden_state2 = outputs2[0]\n",
    "        \n",
    "        first_linear_out = self.linear1( \\\n",
    "            torch.cat((last_hidden_state1[:, 0, : ], last_hidden_state2[:, 0, : ]), dim=-1).view(-1, 2 * 768))\n",
    "        logits = self.linear2(torch.nn.functional.sigmoid(first_linear_out))\n",
    "\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolecularBertGraph().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79747c27-653a-486a-ab4d-3f2c6ec347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'], shuffle = True, batch_size = 64, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"RobertaForMaskedLM + MolCLR (GCN)\",\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/train\": epoch_loss / len(train_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/train\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/train\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/train\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/train\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch['target']\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607de5a0-ec7b-490c-b188-4ef0ad28b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "total_pred_labels = []\n",
    "total_true_labels = []\n",
    "epoch_loss = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "    batch['target'] = batch['target'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**input_batch)\n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "\n",
    "total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "\n",
    "wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "029db7587ec14fab8eb1b11fb0bc47cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2e5b9dd51f154f97821f821d3d05e38d",
       "style": "IPY_MODEL_7d32cb53d23549a3866bb35eca080ba1",
       "value": "100%"
      }
     },
     "03672d65066e4a66ad5dac0d3de1419e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c20851e9c4b4f778350fbce1f0a1c48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "210c1eefc4dd4e1ead1400420ae9fd70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2143342c42b443ac952da90be49d7192": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e5b9dd51f154f97821f821d3d05e38d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3689f0c8a5db45e99710d09efa94214f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "398f64c3dbaf4d3eb5c846d949f4fca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_210c1eefc4dd4e1ead1400420ae9fd70",
       "style": "IPY_MODEL_4471576a569e4ed7a55e52ac8247f879",
       "value": "â€‡10000/10000â€‡[00:00&lt;00:00,â€‡11689.51it/s]"
      }
     },
     "3c3c96ab94ae4fdfa1de4ba2a4977b38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "411d7d88be1d4963899e7ae67b03e045": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c58452c908ea4073a9f52b383908856c",
        "IPY_MODEL_a5d526da52a6448ab89a8b629226df20",
        "IPY_MODEL_398f64c3dbaf4d3eb5c846d949f4fca6"
       ],
       "layout": "IPY_MODEL_f096af10074240ad9cee90beb0bfedd6"
      }
     },
     "4471576a569e4ed7a55e52ac8247f879": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "542812d248a54e14af79f4a89e8536e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1c20851e9c4b4f778350fbce1f0a1c48",
       "style": "IPY_MODEL_03672d65066e4a66ad5dac0d3de1419e",
       "value": "â€‡0/10000â€‡[00:00&lt;?,â€‡?it/s]"
      }
     },
     "59972f962eb647e7949b97352d80d55c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_2143342c42b443ac952da90be49d7192",
       "max": 10000,
       "style": "IPY_MODEL_d0afd5e8942f4b0caf92f5173a302ddb"
      }
     },
     "615c8183ce1440548e2a5681a6c6c3c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "666b76087a114e69bb33327e7063e00d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_029db7587ec14fab8eb1b11fb0bc47cd",
        "IPY_MODEL_85ba1e3a4ad64e83821980df6345c7c7",
        "IPY_MODEL_a6b1bbe3f3ba4f3ead3e3a93dd2491e3"
       ],
       "layout": "IPY_MODEL_ba7af72af5d940d9ad87c720e6f4ba4a"
      }
     },
     "7d32cb53d23549a3866bb35eca080ba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "801823505b894380b5c75f2c09a73169": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85ba1e3a4ad64e83821980df6345c7c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e27ee8fe5d10423eb701465c6a990cf0",
       "max": 10000,
       "style": "IPY_MODEL_97ef6d532cd34bc6892833a80859a28a",
       "value": 10000
      }
     },
     "96f2a6fb663644d98d15544afb783db2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9a27604f09794e45a69b314adea00e75",
        "IPY_MODEL_59972f962eb647e7949b97352d80d55c",
        "IPY_MODEL_542812d248a54e14af79f4a89e8536e4"
       ],
       "layout": "IPY_MODEL_615c8183ce1440548e2a5681a6c6c3c4"
      }
     },
     "97ef6d532cd34bc6892833a80859a28a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9a27604f09794e45a69b314adea00e75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3689f0c8a5db45e99710d09efa94214f",
       "style": "IPY_MODEL_3c3c96ab94ae4fdfa1de4ba2a4977b38",
       "value": "â€‡â€‡0%"
      }
     },
     "a5d526da52a6448ab89a8b629226df20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d89a9961b2f94b03a2a631218ed7a7f6",
       "max": 10000,
       "style": "IPY_MODEL_bb92b01fdf294551a6fd4c37921fdeb9",
       "value": 10000
      }
     },
     "a6b1bbe3f3ba4f3ead3e3a93dd2491e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4320889897247a2b088960f6500ceed",
       "style": "IPY_MODEL_801823505b894380b5c75f2c09a73169",
       "value": "â€‡10000/10000â€‡[00:00&lt;00:00,â€‡11663.25it/s]"
      }
     },
     "af2894528037473db78ef750827aa9d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ba7af72af5d940d9ad87c720e6f4ba4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb92b01fdf294551a6fd4c37921fdeb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c58452c908ea4073a9f52b383908856c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f0e4160120b249b684487199dbf693fb",
       "style": "IPY_MODEL_af2894528037473db78ef750827aa9d9",
       "value": "100%"
      }
     },
     "d0afd5e8942f4b0caf92f5173a302ddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d89a9961b2f94b03a2a631218ed7a7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e27ee8fe5d10423eb701465c6a990cf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4320889897247a2b088960f6500ceed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f096af10074240ad9cee90beb0bfedd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f0e4160120b249b684487199dbf693fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
