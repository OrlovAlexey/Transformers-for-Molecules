{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19af74bd-8f87-44d5-ada6-2bcbdcee1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", index=4) if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb854b92-e6b1-4677-92f8-019a47e4f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67fa0b23-8846-4a44-96c3-cc0b9a9d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_bert = 'molberto_ecfp0_2M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d91b4-c4dc-4dba-a04c-e786601aab87",
   "metadata": {},
   "source": [
    "### Upload config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4478096-04a8-4fe1-b1b9-8a8720750818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 512, 'warm_up': 10, 'epochs': 100, 'load_model': 'None', 'eval_every_n_epochs': 1, 'save_every_n_epochs': 5, 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'weight_decay': '1e-5', 'gpu': 'cuda:0', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 768, 'drop_ratio': 0, 'pool': 'mean'}, 'aug': 'node', 'dataset': {'num_workers': 12, 'valid_size': 0.05, 'data_path': 'data/pubchem-10m-clean.txt'}, 'loss': {'temperature': 0.1, 'use_cosine_similarity': True}}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['ecfp2', 'ecfp3', 'Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97ce4a4d-2911-4103-aca3-40843f0745e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...</td>\n",
       "      <td>2246728737 864674487 3217380708 3218693969 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...</td>\n",
       "      <td>2246728737 864674487 2246699815 864942730 3217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...</td>\n",
       "      <td>2246728737 2245384272 2976033787 3189457552 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...</td>\n",
       "      <td>2246728737 3217380708 3218693969 3218693969 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...</td>\n",
       "      <td>2246728737 2245384272 864674487 2246699815 864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CCN1CCN(CC(O)c2ccc(Br)cc2)CC1</td>\n",
       "      <td>2246728737 2245384272 2092489639 2968968094 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1</td>\n",
       "      <td>864942730 2246699815 864662311 2245384272 8479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...</td>\n",
       "      <td>864942730 2246699815 847961216 2976816164 2968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1</td>\n",
       "      <td>2246728737 2245384272 864674487 3217380708 321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1</td>\n",
       "      <td>2246703798 847336149 847961216 3217380708 2041...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles  \\\n",
       "0     COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...   \n",
       "1     COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...   \n",
       "2     CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...   \n",
       "3     Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...   \n",
       "4     CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...   \n",
       "...                                                 ...   \n",
       "9995                      CCN1CCN(CC(O)c2ccc(Br)cc2)CC1   \n",
       "9996         O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1   \n",
       "9997  O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...   \n",
       "9998          CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1   \n",
       "9999                    C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1   \n",
       "\n",
       "                                                  ecfp1  \n",
       "0     2246728737 864674487 3217380708 3218693969 321...  \n",
       "1     2246728737 864674487 2246699815 864942730 3217...  \n",
       "2     2246728737 2245384272 2976033787 3189457552 32...  \n",
       "3     2246728737 3217380708 3218693969 3218693969 32...  \n",
       "4     2246728737 2245384272 864674487 2246699815 864...  \n",
       "...                                                 ...  \n",
       "9995  2246728737 2245384272 2092489639 2968968094 29...  \n",
       "9996  864942730 2246699815 864662311 2245384272 8479...  \n",
       "9997  864942730 2246699815 847961216 2976816164 2968...  \n",
       "9998  2246728737 2245384272 864674487 3217380708 321...  \n",
       "9999  2246703798 847336149 847961216 3217380708 2041...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this because pandas thinks columns with arrays are strings\n",
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411d7d88be1d4963899e7ae67b03e045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae984aa-919e-438b-82bf-76747ac879c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8d0d1-a614-4d8b-958a-ec563f66db70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58e8c4-b226-4247-9ddf-8f69df72376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "def CustomDataCollator():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c61aaf7e-b46e-42f0-8981-67d2006f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [\n",
    "    Chem.rdchem.BondType.SINGLE, \n",
    "    Chem.rdchem.BondType.DOUBLE, \n",
    "    Chem.rdchem.BondType.TRIPLE, \n",
    "    Chem.rdchem.BondType.AROMATIC\n",
    "]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5d0bdc0-89c4-494d-a76a-5cc7071cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataset: pd.DataFrame, tokenizer, node_mask_percent=0.25, edge_mask_percent=0.25):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.node_mask_percent = node_mask_percent\n",
    "        self.edge_mask_percent = edge_mask_percent\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.model_max_len = 512\n",
    "\n",
    "    def get_graph_from_smiles(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return torch.tensor([[], []], dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    0\n",
    "    \n",
    "        N = mol.GetNumAtoms()\n",
    "        M = mol.GetNumBonds()\n",
    "    \n",
    "        type_idx = []\n",
    "        chirality_idx = []\n",
    "        atomic_number = []\n",
    "        \n",
    "        for atom in mol.GetAtoms():\n",
    "            type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "            chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "            atomic_number.append(atom.GetAtomicNum())\n",
    "        \n",
    "        x1 = torch.tensor(type_idx, dtype=torch.long).view(-1,1)\n",
    "        x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1,1)\n",
    "        node_feat = torch.cat([x1, x2], dim=-1)\n",
    "    \n",
    "        row, col, edge_feat = [], [], []\n",
    "        for bond in mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            row += [start, end]\n",
    "            col += [end, start]\n",
    "            \n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "    \n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_feat, dtype=torch.long)\n",
    "        num_nodes = N\n",
    "        num_edges = M\n",
    "        return node_feat, edge_index, edge_attr, num_nodes, num_edges\n",
    "\n",
    "    def get_augmented_graph_copy(self, node_feat, edge_index, edge_attr, N, M):\n",
    "        num_mask_nodes = max([1, math.floor(self.node_mask_percent * N)])\n",
    "        num_mask_edges = max([0, math.floor(self.edge_mask_percent * M)])\n",
    "        \n",
    "        mask_nodes = random.sample(list(range(N)), num_mask_nodes)\n",
    "        mask_edges_single = random.sample(list(range(M)), num_mask_edges)\n",
    "        mask_edges = [2*i for i in mask_edges_single] + [2*i+1 for i in mask_edges_single]\n",
    "\n",
    "        node_feat_new = deepcopy(node_feat)\n",
    "        for atom_idx in mask_nodes:\n",
    "            node_feat_new[atom_idx, :] = torch.tensor([len(ATOM_LIST), 0])\n",
    "        edge_index_new = torch.zeros((2, 2*(M - num_mask_edges)), dtype=torch.long)\n",
    "        edge_attr_new = torch.zeros((2*(M - num_mask_edges), 2), dtype=torch.long)\n",
    "        count = 0\n",
    "        for bond_idx in range(2*M):\n",
    "            if bond_idx not in mask_edges:\n",
    "                edge_index_new[:, count] = edge_index[:, bond_idx]\n",
    "                edge_attr_new[count, :] = edge_attr[bond_idx, :]\n",
    "                count += 1\n",
    "        return Data(x=node_feat_new, edge_index=edge_index_new, edge_attr=edge_attr_new)\n",
    "\n",
    "    def tokenize(self, item):\n",
    "        return self.tokenizer(item, truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "    def mlm(self, tensor):\n",
    "        rand = torch.rand(tensor.shape)\n",
    "        # mask random 15% where token is not 0 <s>, 1 <pad>, or 2 <s/>\n",
    "        mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "        selection = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "        # mask tensor, token == 4 is our mask token\n",
    "        tensor[selection] = 4\n",
    "        return tensor\n",
    "\n",
    "    def apply_mlm(self, sample):\n",
    "        labels = torch.tensor(sample.input_ids)\n",
    "        mask = torch.tensor(sample.attention_mask)\n",
    "        input_ids = self.mlm(labels.detach().clone())\n",
    "        return Data(labels=labels, mask=mask, input_ids=input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        node_feat, edge_index, edge_attr, num_nodes, num_edges = self.get_graph_from_smiles(self.dataset['Smiles'][index])\n",
    "\n",
    "        data_i = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "        data_j = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "\n",
    "        ecfp = self.dataset['ecfp1'][index]\n",
    "        data_for_bert = self.apply_mlm(self.tokenize(ecfp))\n",
    "        return data_for_bert, data_i, data_j\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "990d0346-4204-4edd-a947-de80e85a685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_bert)\n",
    "dataset = MoleculeDataset(dataframe, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef882144-9701-4c8e-b169-0e11113172b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(config['dataset']['valid_size'] * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset, batch_size = batch_size, sampler=valid_sampler,\n",
    "    num_workers=config['dataset']['num_workers'], drop_last=True\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset, batch_size = batch_size, sampler=valid_sampler,\n",
    "    num_workers=config['dataset']['num_workers'], drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4d1a3-725a-49d1-8905-f4755cd07bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RobertaConfig' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaForMaskedLM\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaConfig\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgin\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mginet_molclr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GINet \u001b[38;5;28;01mas\u001b[39;00m GraphModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RobertaConfig' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "if config['model_type'] == 'gin':\n",
    "    from models.ginet_molclr import GINet as GraphModel\n",
    "elif config['model_type'] == 'gcn':\n",
    "    from models.gcn_molclr import GCN as GraphModel\n",
    "from MolCLR.utils.nt_xent import NTXentLoss\n",
    "\n",
    "class MolecularBertGraph(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularPropertiesClassification, self).__init__()\n",
    "\n",
    "        config = RobertaConfig(\n",
    "            vocab_size=30_522,\n",
    "            max_position_embeddings=514,\n",
    "            hidden_size=768,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1\n",
    "        )\n",
    "        self.bert = RobertaForMaskedLM(config)\n",
    "        \n",
    "        self.graph_model = GraphModel(**config[\"model\"]).to(self.device)\n",
    "        # self.graph_model = self._load_pre_trained_weights(self.graph_model)\n",
    "\n",
    "        self.out_graph_linear = torch.nn.Linear(768 * 2, 768, bias=True)\n",
    "\n",
    "        # contrastive loss for MolCLR\n",
    "        self.nt_xent_criterion = NTXentLoss(device, config['batch_size'], **config['loss'])\n",
    "\n",
    "    def forward(self, bert_batch, graph_batch1, graph_batch2):\n",
    "        bert_output = self.bert(input_ids=bert_batch['input_ids'], \n",
    "                                 attention_mask=bert_batch['attention_mask'],\n",
    "                                 labels=bert_batch['labels'])\n",
    "        bert_loss = bert_output.loss\n",
    "        bert_emb = bert_output.hidden_states[0]\n",
    "\n",
    "        graph_loss, hidden_states_1, hidden_states_2 = self.graph_step(graph_batch1, graph_batch2)\n",
    "        graph_emb = self.out_graph_linear(torch.cat(hidden_states_1, hidden_states_2, dim=-1))\n",
    "        \n",
    "        \n",
    "        # first_linear_out = self.linear1( \\\n",
    "        #     torch.cat((last_hidden_state1[:, 0, : ], last_hidden_state2[:, 0, : ]), dim=-1).view(-1, 2 * 768))\n",
    "\n",
    "        return bert_loss, bert_emb, graph_loss, graph_emb\n",
    "\n",
    "    def graph_step(self, xis, xjs):\n",
    "        # get the representations and the projections\n",
    "        ris, zis = self.graph_model(xis)  # [N,C]\n",
    "    \n",
    "        # get the representations and the projections\n",
    "        rjs, zjs = self.graph_model(xjs)  # [N,C]\n",
    "    \n",
    "        # normalize projection feature vectors\n",
    "        zis = torch.nn.functional.normalize(zis, dim=1)\n",
    "        zjs = torch.nn.functional.normalize(zjs, dim=1)\n",
    "    \n",
    "        loss = self.nt_xent_criterion(zis, zjs)\n",
    "        return loss, ris, rjs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolecularBertGraph().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1428e13-d841-45e7-a885-919d4670a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), config['init_lr'], \n",
    "    weight_decay=eval(config['weight_decay'])\n",
    ")\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, T_max=config['epochs']-config['warm_up'], \n",
    "    eta_min=0, last_epoch=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"RobertaForMaskedLM + MolCLR (GCN)\",\n",
    "    config={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a426df-461e-4180-9186-c5471b4df374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoints_folder = os.path.join(self.writer.log_dir, 'checkpoints')\n",
    "# _save_config_file(model_checkpoints_folder)\n",
    "\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch_counter in range(num_epoch): # range(config['epochs']):\n",
    "    model.train()\n",
    "    for batch_counter, (bert_batch, graph_batch1, graph_batch2) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bert_batch = bert_batch.to(device)\n",
    "        graph_batch1 = graph_batch1.to(device)\n",
    "        graph_batch2 = graph_batch2.to(device)\n",
    "\n",
    "        loss_bert, loss_graph, bimodal_loss = model(bert_batch, graph_batch1, graph_batch2)\n",
    "\n",
    "        if n_iter % self.config['log_every_n_steps'] == 0:\n",
    "            # self.writer.add_scalar('train_loss', loss, global_step=n_iter)\n",
    "            # self.writer.add_scalar('cosine_lr_decay', scheduler.get_last_lr()[0], global_step=n_iter)\n",
    "            print(epoch_counter, batch_counter, loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "\n",
    "    # validate the model if requested\n",
    "    if epoch_counter % self.config['eval_every_n_epochs'] == 0:\n",
    "        model.eval()\n",
    "        valid_loss = self._validate(model, valid_loader)\n",
    "        print(epoch_counter, bn, valid_loss, '(validation)')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            # save the model weights\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "    \n",
    "        self.writer.add_scalar('validation_loss', valid_loss, global_step=valid_n_iter)\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    if (epoch_counter+1) % self.config['save_every_n_epochs'] == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model_{}.pth'.format(str(epoch_counter))))\n",
    "\n",
    "    # warmup for the first few epochs\n",
    "    if epoch_counter >= config['warm_up']:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f67d5-c7f4-4ea0-959f-b1a990387a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        logits = model(**input_batch)\n",
    "        \n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/train\": epoch_loss / len(train_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/train\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/train\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/train\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/train\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "\n",
    "    model.eval()\n",
    "    total_pred_labels = []\n",
    "    total_true_labels = []\n",
    "    epoch_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "        batch['target'] = batch['target'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**input_batch)\n",
    "            loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pred_labels = torch.argmax(logits, dim=-1)\n",
    "            true_labels = batch['target']\n",
    "            total_pred_labels.append(pred_labels)\n",
    "            total_true_labels.append(true_labels)\n",
    "        \n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "    total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "    \n",
    "    wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "    wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "    wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "    wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bd8ec-528b-4b88-946f-85308c74081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607de5a0-ec7b-490c-b188-4ef0ad28b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], batch_size = 64, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "total_pred_labels = []\n",
    "total_true_labels = []\n",
    "epoch_loss = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    input_batch = { k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask'] }\n",
    "    batch['target'] = batch['target'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**input_batch)\n",
    "        loss = loss_func(logits.view(-1, 2), batch['target'].view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pred_labels = torch.argmax(logits, dim=-1)\n",
    "        true_labels = batch['target']\n",
    "        total_pred_labels.append(pred_labels)\n",
    "        total_true_labels.append(true_labels)\n",
    "\n",
    "total_pred_labels = torch.cat(total_pred_labels).cpu().detach().numpy()\n",
    "total_true_labels = torch.cat(total_true_labels).cpu().detach().numpy()\n",
    "\n",
    "wandb.log({\"loss/validation\": epoch_loss / len(eval_dataloader)}, step=epoch)\n",
    "wandb.log({\"accuracy/validation\": accuracy_score(total_true_labels, total_pred_labels)}, step=epoch)\n",
    "wandb.log({\"f1/validation\": f1_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"precision/validation\": precision_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)\n",
    "wandb.log({\"recall/validation\": recall_score(total_true_labels, total_pred_labels, average='micro')}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a96b63-ec67-4374-968e-bd71ff08c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "029db7587ec14fab8eb1b11fb0bc47cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2e5b9dd51f154f97821f821d3d05e38d",
       "style": "IPY_MODEL_7d32cb53d23549a3866bb35eca080ba1",
       "value": "100%"
      }
     },
     "03672d65066e4a66ad5dac0d3de1419e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c20851e9c4b4f778350fbce1f0a1c48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "210c1eefc4dd4e1ead1400420ae9fd70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2143342c42b443ac952da90be49d7192": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e5b9dd51f154f97821f821d3d05e38d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3689f0c8a5db45e99710d09efa94214f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "398f64c3dbaf4d3eb5c846d949f4fca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_210c1eefc4dd4e1ead1400420ae9fd70",
       "style": "IPY_MODEL_4471576a569e4ed7a55e52ac8247f879",
       "value": " 10000/10000 [00:00&lt;00:00, 11689.51it/s]"
      }
     },
     "3c3c96ab94ae4fdfa1de4ba2a4977b38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "411d7d88be1d4963899e7ae67b03e045": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c58452c908ea4073a9f52b383908856c",
        "IPY_MODEL_a5d526da52a6448ab89a8b629226df20",
        "IPY_MODEL_398f64c3dbaf4d3eb5c846d949f4fca6"
       ],
       "layout": "IPY_MODEL_f096af10074240ad9cee90beb0bfedd6"
      }
     },
     "4471576a569e4ed7a55e52ac8247f879": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "542812d248a54e14af79f4a89e8536e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1c20851e9c4b4f778350fbce1f0a1c48",
       "style": "IPY_MODEL_03672d65066e4a66ad5dac0d3de1419e",
       "value": " 0/10000 [00:00&lt;?, ?it/s]"
      }
     },
     "59972f962eb647e7949b97352d80d55c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_2143342c42b443ac952da90be49d7192",
       "max": 10000,
       "style": "IPY_MODEL_d0afd5e8942f4b0caf92f5173a302ddb"
      }
     },
     "615c8183ce1440548e2a5681a6c6c3c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "666b76087a114e69bb33327e7063e00d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_029db7587ec14fab8eb1b11fb0bc47cd",
        "IPY_MODEL_85ba1e3a4ad64e83821980df6345c7c7",
        "IPY_MODEL_a6b1bbe3f3ba4f3ead3e3a93dd2491e3"
       ],
       "layout": "IPY_MODEL_ba7af72af5d940d9ad87c720e6f4ba4a"
      }
     },
     "7d32cb53d23549a3866bb35eca080ba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "801823505b894380b5c75f2c09a73169": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85ba1e3a4ad64e83821980df6345c7c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e27ee8fe5d10423eb701465c6a990cf0",
       "max": 10000,
       "style": "IPY_MODEL_97ef6d532cd34bc6892833a80859a28a",
       "value": 10000
      }
     },
     "96f2a6fb663644d98d15544afb783db2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9a27604f09794e45a69b314adea00e75",
        "IPY_MODEL_59972f962eb647e7949b97352d80d55c",
        "IPY_MODEL_542812d248a54e14af79f4a89e8536e4"
       ],
       "layout": "IPY_MODEL_615c8183ce1440548e2a5681a6c6c3c4"
      }
     },
     "97ef6d532cd34bc6892833a80859a28a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9a27604f09794e45a69b314adea00e75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3689f0c8a5db45e99710d09efa94214f",
       "style": "IPY_MODEL_3c3c96ab94ae4fdfa1de4ba2a4977b38",
       "value": "  0%"
      }
     },
     "a5d526da52a6448ab89a8b629226df20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d89a9961b2f94b03a2a631218ed7a7f6",
       "max": 10000,
       "style": "IPY_MODEL_bb92b01fdf294551a6fd4c37921fdeb9",
       "value": 10000
      }
     },
     "a6b1bbe3f3ba4f3ead3e3a93dd2491e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4320889897247a2b088960f6500ceed",
       "style": "IPY_MODEL_801823505b894380b5c75f2c09a73169",
       "value": " 10000/10000 [00:00&lt;00:00, 11663.25it/s]"
      }
     },
     "af2894528037473db78ef750827aa9d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ba7af72af5d940d9ad87c720e6f4ba4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb92b01fdf294551a6fd4c37921fdeb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c58452c908ea4073a9f52b383908856c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f0e4160120b249b684487199dbf693fb",
       "style": "IPY_MODEL_af2894528037473db78ef750827aa9d9",
       "value": "100%"
      }
     },
     "d0afd5e8942f4b0caf92f5173a302ddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d89a9961b2f94b03a2a631218ed7a7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e27ee8fe5d10423eb701465c6a990cf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4320889897247a2b088960f6500ceed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f096af10074240ad9cee90beb0bfedd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f0e4160120b249b684487199dbf693fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
