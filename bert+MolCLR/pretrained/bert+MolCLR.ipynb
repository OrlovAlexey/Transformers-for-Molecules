{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e3494b-0296-4bb8-9b07-48a55533413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.require(\"service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/alexeyorlov53/.netrc\n"
     ]
    }
   ],
   "source": [
    "!python3 -m wandb login eb7b1964fb84cd81de96b2a273ecf2bb6254aeac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d91b4-c4dc-4dba-a04c-e786601aab87",
   "metadata": {},
   "source": [
    "### Upload config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4478096-04a8-4fe1-b1b9-8a8720750818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16, 'warm_up': 10, 'epochs': 100, 'load_graph_model': 'pretrained_gcn', 'save_every_n_epochs': 5, 'fp16_precision': False, 'init_lr': 5e-05, 'weight_decay': '1e-5', 'gpu': 'cuda:2', 'pretrained_roberta_name': 'molberto_ecfp0_2M', 'roberta_model': {'vocab_size': 30522, 'max_position_embeddings': 514, 'hidden_size': 768, 'num_attention_heads': 12, 'num_hidden_layers': 6, 'type_vocab_size': 1}, 'graph_model_type': 'gcn', 'graph_model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 512, 'drop_ratio': 0, 'pool': 'mean'}, 'graph_aug': 'node', 'dataset': {'num_workers': 12, 'valid_size': 0.1}, 'ntxent_loss': {'temperature': 0.1, 'use_cosine_similarity': True}, 'loss_params': {'alpha': 1.0, 'beta': 1.0, 'gamma': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b16779-4235-42fe-9091-531e93496fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 16\n"
     ]
    }
   ],
   "source": [
    "print('batch_size =', config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8caa6fa0-9b19-4665-81b8-b122a0c18ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "print('running on device:', config['gpu'])\n",
    "device = torch.device(config['gpu']) if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4d265d-3a4d-4ec1-b616-18805240e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_config_file(config, log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    with open(os.path.join(log_dir, 'config.yml'), 'w') as outfile:\n",
    "        yaml.dump(config, outfile, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0acb3637-c146-45dc-a1d3-d9ef1363d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['ecfp2', 'ecfp3', 'Molecular Weight', 'Bioactivities', 'AlogP', 'Polar Surface Area', 'CX Acidic pKa', 'CX Basic pKa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ce4a4d-2911-4103-aca3-40843f0745e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>ecfp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...</td>\n",
       "      <td>['2246728737', '864674487', '3217380708', '321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...</td>\n",
       "      <td>['2246728737', '864674487', '2246699815', '864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...</td>\n",
       "      <td>['2246728737', '2245384272', '2976033787', '31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...</td>\n",
       "      <td>['2246728737', '3217380708', '3218693969', '32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...</td>\n",
       "      <td>['2246728737', '2245384272', '864674487', '224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CCN1CCN(CC(O)c2ccc(Br)cc2)CC1</td>\n",
       "      <td>['2246728737', '2245384272', '2092489639', '29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1</td>\n",
       "      <td>['864942730', '2246699815', '864662311', '2245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...</td>\n",
       "      <td>['864942730', '2246699815', '847961216', '2976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1</td>\n",
       "      <td>['2246728737', '2245384272', '864674487', '321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1</td>\n",
       "      <td>['2246703798', '847336149', '847961216', '3217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles  \\\n",
       "0     COc1cc(C2(C)CCCc3nc(SCc4ncccn4)n(-c4ccc(F)cc4)...   \n",
       "1     COC(=O)c1sc(NC(=O)C2c3ccccc3Oc3ccccc32)c(C(=O)...   \n",
       "2     CC[C@H]1OC(=O)C[C@@H](O)[C@H](C)[C@@H](O[C@@H]...   \n",
       "3     Cc1cccc(-n2cc(C(=O)N3CCC[C@@H]([n+]4cc[nH]c4)C...   \n",
       "4     CCOC(=O)[C@H](C1CC1)N1C(=O)[C@@H](CC(=O)O)C[C@...   \n",
       "...                                                 ...   \n",
       "9995                      CCN1CCN(CC(O)c2ccc(Br)cc2)CC1   \n",
       "9996         O=C(O)CNC(=O)CNC(=O)CNC(=O)CSC(=O)c1ccccc1   \n",
       "9997  O=C(N[C@@]12CCC[C@@](C#Cc3ccccn3)(CC1)C2)c1ccc...   \n",
       "9998          CCOc1ccccc1-c1cc(C(=O)N2CCOCC2)c2ccccc2n1   \n",
       "9999                    C(=N/Nc1nc2ccccc2[nH]1)\\c1cccs1   \n",
       "\n",
       "                                                  ecfp1  \n",
       "0     ['2246728737', '864674487', '3217380708', '321...  \n",
       "1     ['2246728737', '864674487', '2246699815', '864...  \n",
       "2     ['2246728737', '2245384272', '2976033787', '31...  \n",
       "3     ['2246728737', '3217380708', '3218693969', '32...  \n",
       "4     ['2246728737', '2245384272', '864674487', '224...  \n",
       "...                                                 ...  \n",
       "9995  ['2246728737', '2245384272', '2092489639', '29...  \n",
       "9996  ['864942730', '2246699815', '864662311', '2245...  \n",
       "9997  ['864942730', '2246699815', '847961216', '2976...  \n",
       "9998  ['2246728737', '2245384272', '864674487', '321...  \n",
       "9999  ['2246703798', '847336149', '847961216', '3217...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this because pandas thinks columns with arrays are strings\n",
    "def preprocess_data_dataset(df, column):\n",
    "    for row in tqdm(range(len(df))):\n",
    "        str_ints = eval(df.iloc[row][column])\n",
    "        str_fingerprint = ' '.join(str_ints)\n",
    "        df.at[row, column] = str_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 10004.93it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_data_dataset(dataframe, 'ecfp1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287894eb-5d8b-4d23-ab1c-9d3a63a35b8c",
   "metadata": {},
   "source": [
    "### Create Molecule Dataset\n",
    "##### It will generate torch_geometric.data.Data objects for both bert and GIN/GCN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61aaf7e-b46e-42f0-8981-67d2006f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [\n",
    "    Chem.rdchem.BondType.SINGLE, \n",
    "    Chem.rdchem.BondType.DOUBLE, \n",
    "    Chem.rdchem.BondType.TRIPLE, \n",
    "    Chem.rdchem.BondType.AROMATIC\n",
    "]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d0bdc0-89c4-494d-a76a-5cc7071cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataset: pd.DataFrame, tokenizer, node_mask_percent=0.25, edge_mask_percent=0.25):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.node_mask_percent = node_mask_percent\n",
    "        self.edge_mask_percent = edge_mask_percent\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.model_max_len = 512\n",
    "\n",
    "    def get_graph_from_smiles(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return torch.tensor([[], []], dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    0\n",
    "    \n",
    "        N = mol.GetNumAtoms()\n",
    "        M = mol.GetNumBonds()\n",
    "    \n",
    "        type_idx = []\n",
    "        chirality_idx = []\n",
    "        atomic_number = []\n",
    "        \n",
    "        for atom in mol.GetAtoms():\n",
    "            type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "            chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "            atomic_number.append(atom.GetAtomicNum())\n",
    "        \n",
    "        x1 = torch.tensor(type_idx, dtype=torch.long).view(-1,1)\n",
    "        x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1,1)\n",
    "        node_feat = torch.cat([x1, x2], dim=-1)\n",
    "    \n",
    "        row, col, edge_feat = [], [], []\n",
    "        for bond in mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            row += [start, end]\n",
    "            col += [end, start]\n",
    "            \n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "    \n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_feat, dtype=torch.long)\n",
    "        num_nodes = N\n",
    "        num_edges = M\n",
    "        return node_feat, edge_index, edge_attr, num_nodes, num_edges\n",
    "\n",
    "    def get_augmented_graph_copy(self, node_feat, edge_index, edge_attr, N, M):\n",
    "        num_mask_nodes = max([1, math.floor(self.node_mask_percent * N)])\n",
    "        num_mask_edges = max([0, math.floor(self.edge_mask_percent * M)])\n",
    "        \n",
    "        mask_nodes = random.sample(list(range(N)), num_mask_nodes)\n",
    "        mask_edges_single = random.sample(list(range(M)), num_mask_edges)\n",
    "        mask_edges = [2*i for i in mask_edges_single] + [2*i+1 for i in mask_edges_single]\n",
    "\n",
    "        node_feat_new = deepcopy(node_feat)\n",
    "        for atom_idx in mask_nodes:\n",
    "            node_feat_new[atom_idx, :] = torch.tensor([len(ATOM_LIST), 0])\n",
    "        edge_index_new = torch.zeros((2, 2*(M - num_mask_edges)), dtype=torch.long)\n",
    "        edge_attr_new = torch.zeros((2*(M - num_mask_edges), 2), dtype=torch.long)\n",
    "        count = 0\n",
    "        for bond_idx in range(2*M):\n",
    "            if bond_idx not in mask_edges:\n",
    "                edge_index_new[:, count] = edge_index[:, bond_idx]\n",
    "                edge_attr_new[count, :] = edge_attr[bond_idx, :]\n",
    "                count += 1\n",
    "        return Data(x=node_feat_new, edge_index=edge_index_new, edge_attr=edge_attr_new)\n",
    "\n",
    "    def tokenize(self, item):\n",
    "        return self.tokenizer(item, truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "    def mlm(self, tensor):\n",
    "        rand = torch.rand(tensor.shape)\n",
    "        # mask random 15% where token is not 0 <s>, 1 <pad>, or 2 <s/>\n",
    "        mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "        selection = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "        # mask tensor, token == 4 is our mask token\n",
    "        tensor[selection] = 4\n",
    "        return tensor\n",
    "\n",
    "    def apply_mlm(self, sample):\n",
    "        labels = torch.tensor(sample.input_ids)\n",
    "        attention_mask = torch.tensor(sample.attention_mask)\n",
    "        input_ids = self.mlm(labels.detach().clone())\n",
    "        return Data(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        node_feat, edge_index, edge_attr, num_nodes, num_edges = self.get_graph_from_smiles(self.dataset['Smiles'][index])\n",
    "\n",
    "        data_i = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "        data_j = self.get_augmented_graph_copy(node_feat, edge_index, edge_attr, num_nodes, num_edges)\n",
    "\n",
    "        ecfp = self.dataset['ecfp1'][index]\n",
    "        data_for_bert = self.apply_mlm(self.tokenize(ecfp))\n",
    "        return data_for_bert, data_i, data_j\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get(self):\n",
    "        pass\n",
    "    def len(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "990d0346-4204-4edd-a947-de80e85a685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_bert = 'molberto_ecfp0_2M'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_bert)\n",
    "dataset = MoleculeDataset(dataframe, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef882144-9701-4c8e-b169-0e11113172b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(config['dataset']['valid_size'] * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset, batch_size=config['batch_size'], sampler=train_sampler,\n",
    "    num_workers=config['dataset']['num_workers'], drop_last=True\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset, batch_size=config['batch_size'], sampler=valid_sampler,\n",
    "    num_workers=config['dataset']['num_workers'], drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11cc2bf1-7318-4f29-afdb-8d3b70794bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NTXentLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device, batch_size, temperature, use_cosine_similarity):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n",
    "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_similarity_function(self, use_cosine_similarity):\n",
    "        if use_cosine_similarity:\n",
    "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "            return self._cosine_simililarity\n",
    "        else:\n",
    "            return self._dot_simililarity\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        diag = np.eye(2 * self.batch_size)\n",
    "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
    "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
    "        mask = torch.from_numpy((diag + l1 + l2))\n",
    "        mask = (1 - mask).type(torch.bool)\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dot_simililarity(x, y):\n",
    "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, C, 2N)\n",
    "        # v shape: (N, 2N)\n",
    "        return v\n",
    "\n",
    "    def _cosine_simililarity(self, x, y):\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, 2N, C)\n",
    "        # v shape: (N, 2N)\n",
    "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
    "        return v\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        representations = torch.cat([zjs, zis], dim=0)\n",
    "\n",
    "        similarity_matrix = self.similarity_function(representations, representations)\n",
    "\n",
    "        # filter out the scores from the positive samples\n",
    "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
    "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
    "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n",
    "\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        logits = logits.abs() + 0.0001\n",
    "        logits = torch.log(logits)\n",
    "        logits /= self.temperature\n",
    "        \n",
    "        labels = torch.zeros(2 * self.batch_size).to(self.device).long()\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        return loss / (2 * self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "if config['graph_model_type'] == 'gin':\n",
    "    from MolCLR.models.ginet_molclr import GINet as GraphModel\n",
    "elif config['graph_model_type'] == 'gcn':\n",
    "    from MolCLR.models.gcn_molclr import GCN as GraphModel\n",
    "else:\n",
    "    raise ValueError('GNN model is not defined in config.')\n",
    "\n",
    "class MolecularBertGraph(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularBertGraph, self).__init__()\n",
    "        self.batch_size = config['batch_size']\n",
    "\n",
    "        roberta_config = RobertaConfig(**config['roberta_model'])\n",
    "        self.bert = RobertaForMaskedLM(roberta_config).from_pretrained(config['pretrained_roberta_name'], \n",
    "                                                                       config=roberta_config)\n",
    "        self.graph_model = GraphModel(**config['graph_model'])\n",
    "        # self.graph_model = self._load_graph_pretrained_weights(self.graph_model)\n",
    "\n",
    "        self.out_graph_linear = torch.nn.Linear(2 * config['graph_model']['feat_dim'], \n",
    "                                                config['roberta_model']['hidden_size'], bias=True)\n",
    "        # contrastive loss for MolCLR\n",
    "        self.nt_xent_criterion = NTXentLoss(device, self.batch_size, **config['ntxent_loss'])\n",
    "        # cosine distance as loss between models\n",
    "        self.cosine_sim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, bert_batch, graph_batch1, graph_batch2):\n",
    "        bert_output = self.bert(input_ids=bert_batch['input_ids'].view(self.batch_size, -1), \n",
    "                                 attention_mask=bert_batch['attention_mask'].view(self.batch_size, -1),\n",
    "                                 labels=bert_batch['labels'].view(self.batch_size, -1), output_hidden_states=True)\n",
    "        bert_loss = bert_output.loss\n",
    "        bert_emb = bert_output.hidden_states[0][:, 0, :] # take emb for CLS token\n",
    "\n",
    "        graph_loss, hidden_states_1, hidden_states_2 = self.graph_step(graph_batch1, graph_batch2)\n",
    "        graph_emb = self.out_graph_linear(torch.cat((hidden_states_1, hidden_states_2), dim=-1))\n",
    "\n",
    "        # bimodal_loss = ((1 - self.cosine_sim(bert_emb, graph_emb))**2).mean()\n",
    "        bimodal_loss = self.nt_xent_criterion(bert_emb, graph_emb)\n",
    "        return bert_loss, graph_loss, bimodal_loss\n",
    "\n",
    "    def graph_step(self, xis, xjs):\n",
    "        # get the representations and the projections\n",
    "        ris, zis = self.graph_model(xis)  # [N,C]\n",
    "    \n",
    "        # get the representations and the projections\n",
    "        rjs, zjs = self.graph_model(xjs)  # [N,C]\n",
    "    \n",
    "        # normalize projection feature vectors\n",
    "        zis = torch.nn.functional.normalize(zis, dim=1)\n",
    "        zjs = torch.nn.functional.normalize(zjs, dim=1)\n",
    "\n",
    "        loss = self.nt_xent_criterion(zis, zjs)\n",
    "        return loss, ris, rjs\n",
    "        \n",
    "    def _load_graph_pretrained_weights(self, model):\n",
    "        try:\n",
    "            checkpoints_folder = os.path.join('MolCLR', 'ckpt', config['load_graph_model'], 'checkpoints')\n",
    "            print(os.path.join(checkpoints_folder, 'model.pth'))\n",
    "            state_dict = torch.load(os.path.join(checkpoints_folder, 'model.pth'))\n",
    "            \n",
    "            model.load_state_dict(state_dict)\n",
    "            print(\"Loaded pre-trained model with success.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08055762-1a53-49e6-8cd7-71161852abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolecularBertGraph().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14c66953-4356-415d-ac4e-e031126c8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MolecularBertGraph(\n",
      "  (bert): RobertaForMaskedLM(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (graph_model): GCN(\n",
      "    (x_embedding1): Embedding(119, 300)\n",
      "    (x_embedding2): Embedding(3, 300)\n",
      "    (gnns): ModuleList(\n",
      "      (0-4): 5 x GCNConv()\n",
      "    )\n",
      "    (batch_norms): ModuleList(\n",
      "      (0-4): 5 x BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (feat_lin): Linear(in_features=300, out_features=512, bias=True)\n",
      "    (out_lin): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_graph_linear): Linear(in_features=1024, out_features=768, bias=True)\n",
      "  (nt_xent_criterion): NTXentLoss(\n",
      "    (softmax): Softmax(dim=-1)\n",
      "    (_cosine_similarity): CosineSimilarity()\n",
      "    (criterion): CrossEntropyLoss()\n",
      "  )\n",
      "  (cosine_sim): CosineSimilarity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = config['epochs']\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), config['init_lr'], \n",
    "    weight_decay=eval(config['weight_decay'])\n",
    ")\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#     optimizer, T_max=config['epochs']-config['warm_up'], \n",
    "#     eta_min=0, last_epoch=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33morlov-aleksei53\u001b[0m (\u001b[33mmoleculary-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alexeyorlov53/Transformers-for-Molecules/bert+MolCLR/pretrained/wandb/run-20240625_162010-q5uctue8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/q5uctue8' target=\"_blank\">Pretrained RobertaForMaskedLM + pretrained MolCLR (GCN) 10k</a></strong> to <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moleculary-ai/efcp_transformer' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moleculary-ai/efcp_transformer/runs/q5uctue8' target=\"_blank\">https://wandb.ai/moleculary-ai/efcp_transformer/runs/q5uctue8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/moleculary-ai/efcp_transformer/runs/q5uctue8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6d206102b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"Pretrained RobertaForMaskedLM + pretrained MolCLR (GCN) 10k\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training (with validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f660cb2-97a3-4102-b85e-c6e23c84429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = config['loss_params']['alpha']\n",
    "beta = config['loss_params']['beta']\n",
    "gamma = config['loss_params']['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ea2e1e-8d54-4f03-914f-6b6328b5da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96388fce-0dc6-43a3-b800-5133ea476cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    train_tqdm = tqdm(train_dataloader, unit=\"batch\")\n",
    "    train_tqdm.set_description(f'Epoch {epoch_counter}')\n",
    "    bert_loss_sum, graph_model_loss_sum, bimodal_loss_sum, loss_sum = 0, 0, 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for (bert_batch, graph_batch1, graph_batch2) in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bert_batch = bert_batch.to(device)\n",
    "        graph_batch1 = graph_batch1.to(device)\n",
    "        graph_batch2 = graph_batch2.to(device)\n",
    "\n",
    "        bert_loss, graph_loss, bimodal_loss = model(bert_batch, graph_batch1, graph_batch2)\n",
    "\n",
    "        loss = alpha * bert_loss + beta * graph_loss + gamma * bimodal_loss\n",
    "        loss.backward()\n",
    "\n",
    "        bert_loss_sum += bert_loss.item()\n",
    "        graph_model_loss_sum += graph_loss.item()\n",
    "        bimodal_loss_sum += bimodal_loss.item()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_tqdm.set_postfix(loss=loss.item(), bert_loss=bert_loss.item(), graph_loss=graph_loss.item(), bimodal_loss=bimodal_loss.item())\n",
    "    return bert_loss_sum / len(train_dataloader), graph_model_loss_sum / len(train_dataloader), bimodal_loss_sum / len(train_dataloader), loss_sum / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7af92a73-77ad-4bd7-9727-7bb5337fd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop():\n",
    "    eval_tqdm = tqdm(eval_dataloader, unit=\"batch\")\n",
    "    eval_tqdm.set_description(f'Epoch {epoch_counter}')\n",
    "    bert_loss_sum, graph_model_loss_sum, bimodal_loss_sum, loss_sum = 0, 0, 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    for (bert_batch, graph_batch1, graph_batch2) in eval_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bert_batch = bert_batch.to(device)\n",
    "        graph_batch1 = graph_batch1.to(device)\n",
    "        graph_batch2 = graph_batch2.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            bert_loss, graph_loss, bimodal_loss = model(bert_batch, graph_batch1, graph_batch2)\n",
    "\n",
    "        loss = alpha * bert_loss + beta * graph_loss + gamma * bimodal_loss\n",
    "\n",
    "        bert_loss_sum += bert_loss.item()\n",
    "        graph_model_loss_sum += graph_loss.item()\n",
    "        bimodal_loss_sum += bimodal_loss.item()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        eval_tqdm.set_postfix(loss=loss.item(), bert_loss=bert_loss.item(), graph_loss=graph_loss.item(), bimodal_loss=bimodal_loss.item())\n",
    "    return bert_loss_sum / len(eval_dataloader), graph_model_loss_sum / len(eval_dataloader), bimodal_loss_sum / len(eval_dataloader), loss_sum / len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6bb042f-7934-4e54-b202-fe736e4396d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████| 62/62 [00:20<00:00,  3.08batch/s, bert_loss=0.0132, bimodal_loss=54.8, graph_loss=3.39, loss=58.2]\n"
     ]
    }
   ],
   "source": [
    "bert_loss, graph_loss, bimodal_loss, loss = eval_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60dc9568-bd68-4dbd-a797-d756f697c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_loss = 0.012725239319186057\n",
      "graph_loss =  3.3833395934874013\n",
      "bimodal_loss = 52.559547855008034\n",
      "sum of losses = 55.955612613308816\n"
     ]
    }
   ],
   "source": [
    "print('bert_loss =', bert_loss)\n",
    "print('graph_loss = ', graph_loss)\n",
    "print('bimodal_loss =', bimodal_loss)\n",
    "print('sum of losses =', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dabd36a8-610d-4760-a984-79bf17e5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model_checkpoints_folder = os.path.join('ckpts')\n",
    "dir_name = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "log_dir = os.path.join(model_checkpoints_folder, dir_name)\n",
    "_save_config_file(config, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a426df-461e-4180-9186-c5471b4df374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████| 562/562 [06:26<00:00,  1.45batch/s, bert_loss=0.00656, bimodal_loss=9.81, graph_loss=1.13, loss=10.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007989358557951621 1.6952791869428234 11.319391691811992 13.022660201978853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████| 62/62 [00:19<00:00,  3.23batch/s, bert_loss=0.00743, bimodal_loss=13, graph_loss=1.53, loss=14.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.0073110865459086434 1.6785333098903779 9.3007484943636 10.986592908059396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.0086, bimodal_loss=4.65, graph_loss=1.11, loss=5.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007956480351773843 1.4875733537393956 6.564184535864833 8.059714372471982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████| 62/62 [00:19<00:00,  3.19batch/s, bert_loss=0.0063, bimodal_loss=5.53, graph_loss=1.36, loss=6.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007376911505425889 1.5299454648648538 5.768517832602224 7.305840246139034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████| 562/562 [06:30<00:00,  1.44batch/s, bert_loss=0.00842, bimodal_loss=4.38, graph_loss=2.09, loss=6.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008025767536853768 1.4425862434707926 5.416331642038881 6.866943648701461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████| 62/62 [00:17<00:00,  3.49batch/s, bert_loss=0.00977, bimodal_loss=4.89, graph_loss=1.41, loss=6.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.008072700862201953 1.4841395020484924 5.9083679106927685 7.4005801062430105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████| 562/562 [06:27<00:00,  1.45batch/s, bert_loss=0.00544, bimodal_loss=4.02, graph_loss=2.29, loss=6.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008125185062926515 1.3760550672261316 4.7827509722251484 6.166931237190219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████| 62/62 [00:19<00:00,  3.26batch/s, bert_loss=0.00544, bimodal_loss=4.9, graph_loss=1.89, loss=6.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007343835280006451 1.4862409214819632 5.226063032304087 6.719647784386912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.00615, bimodal_loss=4.03, graph_loss=1.72, loss=5.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007965413582166557 1.336401222333365 4.613786784355327 5.958153417526191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████| 62/62 [00:19<00:00,  3.23batch/s, bert_loss=0.00538, bimodal_loss=3.95, graph_loss=1.55, loss=5.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007787514598138871 1.715786793539601 4.667580719917051 6.391155019883187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.0118, bimodal_loss=3.73, graph_loss=1.95, loss=5.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007985612127707866 1.4346057683547622 4.449056195194611 5.891647583225019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████| 62/62 [00:16<00:00,  3.74batch/s, bert_loss=0.0065, bimodal_loss=4.12, graph_loss=1.81, loss=5.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.008077590662475315 1.6444563211933259 4.20133001189078 5.853863969925912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████| 562/562 [06:27<00:00,  1.45batch/s, bert_loss=0.00559, bimodal_loss=3.87, graph_loss=1.12, loss=5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007996226302961226 1.3905536666035228 4.270889707731607 5.669439612758541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████| 62/62 [00:19<00:00,  3.24batch/s, bert_loss=0.0068, bimodal_loss=3.64, graph_loss=1.25, loss=4.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007593946734202966 1.4398000874826986 4.353418104110226 5.800812159815142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████| 562/562 [06:28<00:00,  1.45batch/s, bert_loss=0.00719, bimodal_loss=3.69, graph_loss=1.28, loss=4.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008034338787681956 1.3743587332476077 4.451794335850617 5.834187406662096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████| 62/62 [00:19<00:00,  3.21batch/s, bert_loss=0.00584, bimodal_loss=3.51, graph_loss=1.03, loss=4.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.0077572131056278465 1.395942476487929 3.917857620023912 5.321557283401489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████| 562/562 [06:26<00:00,  1.45batch/s, bert_loss=0.00561, bimodal_loss=3.61, graph_loss=1.04, loss=4.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008037233571488795 1.3364662709397352 3.905933326249445 5.2504368337447955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████| 62/62 [00:16<00:00,  3.68batch/s, bert_loss=0.00615, bimodal_loss=3.73, graph_loss=2.13, loss=5.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007644908780592584 1.4090487735886728 3.8433801474109774 5.260073838695403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.00722, bimodal_loss=6.22, graph_loss=1.62, loss=7.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008067078420683556 1.3113595122120134 4.356950473955093 5.676377052938387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████| 62/62 [00:19<00:00,  3.21batch/s, bert_loss=0.00446, bimodal_loss=3.76, graph_loss=1.56, loss=5.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.00760008372937239 1.4487391191144143 4.097002321673978 5.553341480993455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████████████████| 562/562 [06:30<00:00,  1.44batch/s, bert_loss=0.0103, bimodal_loss=3.54, graph_loss=1.98, loss=5.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008194234022486199 1.3265256417179447 3.925053265595351 5.259773150033374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████| 62/62 [00:19<00:00,  3.24batch/s, bert_loss=0.00806, bimodal_loss=3.46, graph_loss=1.41, loss=4.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007675332280116216 1.3811359126721658 3.703485065890897 5.092296315777686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████| 562/562 [06:26<00:00,  1.45batch/s, bert_loss=0.00833, bimodal_loss=3.75, graph_loss=1.09, loss=4.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008030255245595004 1.3319068326220393 3.737643939320303 5.077581028072859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████| 62/62 [00:19<00:00,  3.22batch/s, bert_loss=0.00575, bimodal_loss=3.45, graph_loss=1.61, loss=5.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007619160625542845 1.4469382935954678 3.7553550774051296 5.209912538528442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████| 562/562 [06:30<00:00,  1.44batch/s, bert_loss=0.00807, bimodal_loss=4.32, graph_loss=1.35, loss=5.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008035762982071771 1.3755684946779678 3.9149762387801745 5.298580489548924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|███████████████████████| 62/62 [00:19<00:00,  3.21batch/s, bert_loss=0.00795, bimodal_loss=4.62, graph_loss=1.82, loss=6.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.00788802181130215 1.4859285498819044 3.9472135151586225 5.44103007162771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.00651, bimodal_loss=3.99, graph_loss=1.44, loss=5.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008127855315134989 1.320514210708625 3.870976698780399 5.199618756134739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████████| 62/62 [00:19<00:00,  3.25batch/s, bert_loss=0.00749, bimodal_loss=3.64, graph_loss=1.41, loss=5.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007226349887317947 1.4491123403272321 3.73506558710529 5.19140427343307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████| 562/562 [06:25<00:00,  1.46batch/s, bert_loss=0.00675, bimodal_loss=3.49, graph_loss=1.14, loss=4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008051353368371247 1.2871967807571234 3.739602294680911 5.034850431930977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████| 62/62 [00:19<00:00,  3.25batch/s, bert_loss=0.00661, bimodal_loss=4.63, graph_loss=0.968, loss=5.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007451166894527212 1.3944765713907057 3.6545000114748554 5.056427763354394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████| 562/562 [06:29<00:00,  1.44batch/s, bert_loss=0.00534, bimodal_loss=3.57, graph_loss=0.52, loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008051816115961195 1.3167755774543803 3.9068199056747543 5.231647293762804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████| 62/62 [00:19<00:00,  3.21batch/s, bert_loss=0.0109, bimodal_loss=3.44, graph_loss=1.5, loss=4.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.00782375683587405 1.4066423648788082 3.7702989270610194 5.1847650235699065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████| 562/562 [06:27<00:00,  1.45batch/s, bert_loss=0.00906, bimodal_loss=3.5, graph_loss=3.07, loss=6.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008057041051449566 3.61256102151718 3.9942186345409243 7.614836715718606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|███████████████████████| 62/62 [00:19<00:00,  3.24batch/s, bert_loss=0.00879, bimodal_loss=3.69, graph_loss=3.46, loss=7.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007590710208000195 3.5794558909631546 3.8927287863146876 7.479775382626441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████| 562/562 [06:26<00:00,  1.45batch/s, bert_loss=0.00837, bimodal_loss=4.01, graph_loss=4.1, loss=8.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008006201065609437 3.5445899004613803 3.856518708514149 7.409114823222585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|███████████████████████| 62/62 [00:19<00:00,  3.19batch/s, bert_loss=0.00451, bimodal_loss=3.48, graph_loss=3.31, loss=6.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.008009641108313394 3.4074941950459636 3.699527963515251 7.1150317884260605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████| 562/562 [06:26<00:00,  1.45batch/s, bert_loss=0.00599, bimodal_loss=4.55, graph_loss=3.02, loss=7.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.00792925346069356 3.4145818104523356 3.746811584645743 7.169322638324996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|███████████████████████| 62/62 [00:19<00:00,  3.24batch/s, bert_loss=0.00486, bimodal_loss=3.67, graph_loss=3.17, loss=6.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007415258325636387 3.4232115514816774 3.7325107474480905 7.163137543585993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████| 562/562 [08:02<00:00,  1.17batch/s, bert_loss=0.0115, bimodal_loss=4.01, graph_loss=4.07, loss=8.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.007946137604436231 3.5553493007646337 3.971539313682882 7.534834756545749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████| 62/62 [00:21<00:00,  2.85batch/s, bert_loss=0.00669, bimodal_loss=3.87, graph_loss=3.9, loss=7.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0.007670880242761585 4.714435800429313 4.0676272492254935 8.78973392517336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  19%|███▉                 | 106/562 [01:38<07:19,  1.04batch/s, bert_loss=0.00667, bimodal_loss=3.57, graph_loss=5.61, loss=9.19]"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch_counter in range(num_epoch):\n",
    "    bert_loss, graph_loss, bimodal_loss, loss = train_loop()\n",
    "    print('train', bert_loss, graph_loss, bimodal_loss, loss)\n",
    "    \n",
    "    wandb.log({\"bert_loss/train\": bert_loss}, step=epoch_counter)\n",
    "    wandb.log({\"graph_loss/train\": graph_loss}, step=epoch_counter)\n",
    "    wandb.log({\"bimodal_loss/train\": bimodal_loss}, step=epoch_counter)\n",
    "    wandb.log({\"loss/train\": loss}, step=epoch_counter)\n",
    "\n",
    "    bert_loss, graph_loss, bimodal_loss, loss = eval_loop()\n",
    "    print('eval', bert_loss, graph_loss, bimodal_loss, loss)\n",
    "\n",
    "    wandb.log({\"bert_loss/eval\": bert_loss}, step=epoch_counter)\n",
    "    wandb.log({\"graph_loss/eval\": graph_loss}, step=epoch_counter)\n",
    "    wandb.log({\"bimodal_loss/eval\": bimodal_loss}, step=epoch_counter)\n",
    "    wandb.log({\"loss/eval\": loss}, step=epoch_counter)\n",
    "    \n",
    "    if loss < best_valid_loss:\n",
    "        best_valid_loss = loss\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, 'model.pth'))\n",
    "    \n",
    "    if (epoch_counter + 1) % config['save_every_n_epochs'] == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, 'model_{}.pth'.format(str(epoch_counter))))\n",
    "\n",
    "    # # warmup for the first few epochs\n",
    "    # if epoch_counter >= config['warm_up']:\n",
    "        # wandb.log({\"cosine_lr_decay\": scheduler.get_last_lr()[0]}, step=epoch_counter)\n",
    "        # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df3a5c-965c-4a66-bd38-a8158398ad58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca196530-c8af-4581-b213-affedb0109db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "045168116a2a4feeb0a2f1a8d68ff384": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "16a6d387456546b3a63e940c86a31bdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_6fd252b4d1594e4d8352a3fdca6ff087",
       "max": 1,
       "style": "IPY_MODEL_57367b85e26d442181cd9c93cc11eed7"
      }
     },
     "17365fe1e7f24cdbb2d05fcdce6be3fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a3ad91f2776c49099e2e4fad5eace739",
        "IPY_MODEL_16a6d387456546b3a63e940c86a31bdc"
       ],
       "layout": "IPY_MODEL_c055c11f48c24dc5b410b4180f5b93d8"
      }
     },
     "189a5bdbe8f04a81b8cb76974e1d54a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "19557758821048cfb18819c30d3b3cca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e5ece06187949ee9117a70c8c146c10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "45ac653c0c434bfbbdd49fe29da3d384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_985ad89facc94fdf8e1b2751eeded620",
       "style": "IPY_MODEL_3e5ece06187949ee9117a70c8c146c10"
      }
     },
     "57367b85e26d442181cd9c93cc11eed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6fd252b4d1594e4d8352a3fdca6ff087": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "985ad89facc94fdf8e1b2751eeded620": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a043c7dea8b34c17916617f9620eacca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_189a5bdbe8f04a81b8cb76974e1d54a3",
       "max": 1,
       "style": "IPY_MODEL_c9bd1208af7f4ac5b8ba534f17119f70"
      }
     },
     "a3ad91f2776c49099e2e4fad5eace739": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_045168116a2a4feeb0a2f1a8d68ff384",
       "style": "IPY_MODEL_d616372b8816479db126c84d172ed24e"
      }
     },
     "c055c11f48c24dc5b410b4180f5b93d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c9bd1208af7f4ac5b8ba534f17119f70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d616372b8816479db126c84d172ed24e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "f3e6a3e2249d4c1ea68603eec5150fd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_45ac653c0c434bfbbdd49fe29da3d384",
        "IPY_MODEL_a043c7dea8b34c17916617f9620eacca"
       ],
       "layout": "IPY_MODEL_19557758821048cfb18819c30d3b3cca"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
